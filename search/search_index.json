{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The main goal of DockSTARTer is to make it quick and easy to get up and running with Docker. You may choose to rely on DockSTARTer for various changes to your Docker system, or use DockSTARTer as a stepping stone and learn to do more advanced configurations. Getting Started System Requirements You must be running a Supported platform or an operating system based on a supported platform. Platforms named below will link to documentation listing compatible versions. You must be logged in as a non-root user with sudo permissions. One Time Setup (required) APT Systems ( Debian , Ubuntu , etc) sudo apt-get install curl git bash -c \"$(curl -fsSL https://get.dockstarter.com)\" sudo reboot Raspbian requires a few extra commands sudo apt-get update sudo apt-get dist-upgrade sudo apt-get install curl git bash -c \"$(curl -fsSL https://get.docker.com)\" bash -c \"$(curl -fsSL https://get.dockstarter.com)\" sudo reboot DNF Systems ( Fedora ) sudo dnf install curl git bash -c \"$(curl -fsSL https://get.dockstarter.com)\" sudo reboot YUM Systems ( CentOS ) sudo yum install curl git bash -c \"$(curl -fsSL https://get.dockstarter.com)\" sudo reboot Alternate install (any system) The standard install above downloads the initial script using a method with some known risks. For those concerned with the security of the above method here is an alternative: ## NOTE: Run the appropriate command for your distro sudo apt-get install curl git sudo dnf install curl git sudo yum install curl git ## NOTE: Do not sudo the next line. git clone https://github.com/GhostWriters/DockSTARTer \"/home/${USER}/.docker\" sudo bash /home/${USER}/.docker/main.sh -i sudo reboot Running DockSTARTer sudo ds To run DockSTARTer use the command above. You should now see the main menu from the screenshots. Select Configuration and then Full Setup and you will be guided through selecting apps and starting containers. See our documentation for more detailed information. Support Click the chat badge to join us on Discord for support! [ Feature Request ] [ Bug Report ] Contributors This project exists thanks to all the people who contribute. Supporters Support the project by donating on Open Collective. Backers Thank you to all our backers! [ Become a backer ] Sponsors Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [ Become a sponsor ] Special Thanks SmartHomeBeginner.com for creating AtoMiC-ToolKit that served as this project's primary inspiration, and later this guide that provided some initial direction with Docker. LinuxServer.io for maintaining the majority of the Docker images used in this project.","title":"Home"},{"location":"#getting-started","text":"","title":"Getting Started"},{"location":"#system-requirements","text":"You must be running a Supported platform or an operating system based on a supported platform. Platforms named below will link to documentation listing compatible versions. You must be logged in as a non-root user with sudo permissions.","title":"System Requirements"},{"location":"#one-time-setup-required","text":"APT Systems ( Debian , Ubuntu , etc) sudo apt-get install curl git bash -c \"$(curl -fsSL https://get.dockstarter.com)\" sudo reboot Raspbian requires a few extra commands sudo apt-get update sudo apt-get dist-upgrade sudo apt-get install curl git bash -c \"$(curl -fsSL https://get.docker.com)\" bash -c \"$(curl -fsSL https://get.dockstarter.com)\" sudo reboot DNF Systems ( Fedora ) sudo dnf install curl git bash -c \"$(curl -fsSL https://get.dockstarter.com)\" sudo reboot YUM Systems ( CentOS ) sudo yum install curl git bash -c \"$(curl -fsSL https://get.dockstarter.com)\" sudo reboot Alternate install (any system) The standard install above downloads the initial script using a method with some known risks. For those concerned with the security of the above method here is an alternative: ## NOTE: Run the appropriate command for your distro sudo apt-get install curl git sudo dnf install curl git sudo yum install curl git ## NOTE: Do not sudo the next line. git clone https://github.com/GhostWriters/DockSTARTer \"/home/${USER}/.docker\" sudo bash /home/${USER}/.docker/main.sh -i sudo reboot","title":"One Time Setup (required)"},{"location":"#running-dockstarter","text":"sudo ds To run DockSTARTer use the command above. You should now see the main menu from the screenshots. Select Configuration and then Full Setup and you will be guided through selecting apps and starting containers. See our documentation for more detailed information.","title":"Running DockSTARTer"},{"location":"#support","text":"Click the chat badge to join us on Discord for support! [ Feature Request ] [ Bug Report ]","title":"Support"},{"location":"#contributors","text":"This project exists thanks to all the people who contribute.","title":"Contributors"},{"location":"#supporters","text":"Support the project by donating on Open Collective.","title":"Supporters"},{"location":"#backers","text":"Thank you to all our backers! [ Become a backer ]","title":"Backers"},{"location":"#sponsors","text":"Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [ Become a sponsor ]","title":"Sponsors"},{"location":"#special-thanks","text":"SmartHomeBeginner.com for creating AtoMiC-ToolKit that served as this project's primary inspiration, and later this guide that provided some initial direction with Docker. LinuxServer.io for maintaining the majority of the Docker images used in this project.","title":"Special Thanks"},{"location":"introduction/","text":"Introduction What DockSTARTer Is DockSTARTer is a script that installs Docker, Compose, and other dependencies for you. DockSTARTer comes with configurations to run various apps. DockSTARTer can be operated through a friendly GUI of terminal menus. DockSTARTer can be operated through commands for more advanced users who do not prefer the GUI. DockSTARTer is here to give you the freedom to choose what you want to run. DockSTARTer allows you to run apps that are not included using Overrides . What DockSTARTer Is Not DockSTARTer is not a premade set of apps that run an exact way (you get to choose what to run and how to run it). DockSTARTer does not configure apps for you (think of it more like installing apps as a service, settings inside the app are still up to you, although our documentation will have reocmmendations). DockSTARTer does not configure storage for you (you may use local storage, or cloud storage, multiple disks, raid, etc). System Requirements Supported Operating Systems You must be running a Supported platform or an operating system based on a supported platform. Platforms named below will link to documentation listing compatible versions. CentOS Debian Fedora Ubuntu Any operating system based on one of the above (ex: Raspbian) should also work as long as you can install the officially supported https://get.docker.com/ script. DockSTARTer will attempt to perform this install for you if possible. Supported Hardware Any x86_64 , armv7l , or aarch64 system should be able to run one of the supported operating systems listed above. ARM CPUs may have a limited selection of supported containers. Windows Support Currently we recommend installing one of the supported platforms above in a VM. In the future we may be able to support the Windows Subsystem for Linux version 2. Videos Getting Started Version Control Visualization","title":"Introduction"},{"location":"introduction/#introduction","text":"","title":"Introduction"},{"location":"introduction/#what-dockstarter-is","text":"DockSTARTer is a script that installs Docker, Compose, and other dependencies for you. DockSTARTer comes with configurations to run various apps. DockSTARTer can be operated through a friendly GUI of terminal menus. DockSTARTer can be operated through commands for more advanced users who do not prefer the GUI. DockSTARTer is here to give you the freedom to choose what you want to run. DockSTARTer allows you to run apps that are not included using Overrides .","title":"What DockSTARTer Is"},{"location":"introduction/#what-dockstarter-is-not","text":"DockSTARTer is not a premade set of apps that run an exact way (you get to choose what to run and how to run it). DockSTARTer does not configure apps for you (think of it more like installing apps as a service, settings inside the app are still up to you, although our documentation will have reocmmendations). DockSTARTer does not configure storage for you (you may use local storage, or cloud storage, multiple disks, raid, etc).","title":"What DockSTARTer Is Not"},{"location":"introduction/#system-requirements","text":"","title":"System Requirements"},{"location":"introduction/#supported-operating-systems","text":"You must be running a Supported platform or an operating system based on a supported platform. Platforms named below will link to documentation listing compatible versions. CentOS Debian Fedora Ubuntu Any operating system based on one of the above (ex: Raspbian) should also work as long as you can install the officially supported https://get.docker.com/ script. DockSTARTer will attempt to perform this install for you if possible.","title":"Supported Operating Systems"},{"location":"introduction/#supported-hardware","text":"Any x86_64 , armv7l , or aarch64 system should be able to run one of the supported operating systems listed above. ARM CPUs may have a limited selection of supported containers.","title":"Supported Hardware"},{"location":"introduction/#windows-support","text":"Currently we recommend installing one of the supported platforms above in a VM. In the future we may be able to support the Windows Subsystem for Linux version 2.","title":"Windows Support"},{"location":"introduction/#videos","text":"Getting Started Version Control Visualization","title":"Videos"},{"location":"advanced/advanced-usage/","text":"Advanced Usage Assuming you already followed the installation steps in the readme, there are also a number of command line switches you can use with DockSTARTer. Command Line Switches Run The Install Script sudo ds -i This script does the following: Update your system using apt-get Install curl , git , grep , and sed (git should already be installed if you started with the install instructions on the main page, but it's here just in case) Install yq - by downloading the binary from source and installing it locally, used for piecing together YAML files Install docker - by downloading via the official docker-install script, used to run containers Install docker machine completion - by downloading the binary from source and installing it locally, provides tab completion for docker in bash shell (just a nice extra to have) Install docker-compose - using python3 pip, allows configuring of containers to be run together instead of individually running each one Install docker compose completion - by downloading the binary from source and installing it locally, provides tab completion for docker-compose in bash shell (just a nice extra to have) When the script finishes it will prompt you to reboot. Run The Compose Generator sudo ds -c This script verifies the dependencies above and installs or updates them as needed, then creates a file ~/.docker/compose/docker-compose.yml based on the variables you configured in your ~/.docker/compose/.env file. The generator script will prompt to run your selected containers after creating the file. We encourage you to have a look at the generated docker-compose.yml file, however if you wish to make changes please consider using overrides. Please review the Technical Info and Overrides pages. If you make any changes to your .env file (such as changing a port or enabling a new app) you need to rerun the generator which will rebuild only the affected containers. Update DockSTARTer sudo ds -u This should get you the latest changes to DockSTARTer. This will also backup and update your .env file. You may separately backup and update your .env file with the following command. sudo ds -e Then you may want to edit your .env file and run the generator again to bring up new apps or changes to existing apps. Setup Your Environment If you do not yet have a ~/.docker/compose/.env file: sudo ds -e Edit the file using something like nano ~/.docker/compose/.env (ctrl+x will prompt to save and exit the nano editor) Universal Section You will need to fill out all of variables in the top most Universal section. You can find your PUID by running id -u ${USER} . You can find your PGID by running id -g ${USER} . Folders should be set to a location that actually exists even if you do not intend to use them (just make an empty folder and ignore it afterwards). Inside DOCKERCONFDIR , a folder for each app will be created for it's configuration. ${TZ} You should make sure your system's timezone is set correctly, and then also supply your timezone in the TZ variable (see List of tz database time zones ). Application Variables Adding Apps You can add the variables required to run an app by running: # sudo ds -a <APPNAME> ## Example: sudo ds -a sonarr Then your .env file fill have a variable named APPNAME_ENABLED that you can true and then run the Compose Generator to start the app. You may also need to fill in or adjust any other variables prefixed with the APPNAME_ that you're enabling. This is the best place to change your default ports. Please note, Portainer and Ouroboros are enabled by default. Portainer provides a snazzy management interface at your.ip.address:9000 and Ouroboros checks for updates to the Containers you are using, NOT DockSTARTer itself. See here for a (little) more or you can disable them if you wish. Removing Apps You can remove the variables for an app by running: # sudo ds -r <APPNAME> ## Example: sudo ds -r sonarr You can also remove all variables for all apps that are disabled by running: sudo ds -r You will be prompted individually for each app and shown what will be removed. Cleanup Unused Docker Resources sudo ds -p This cleans up the DS install, p stands for prune in this case. This recovers space from old images if they were somehow left over. What Is appdata If you've heard other people talk about an appdata folder and not been sure what they meant, it's what we have had as our default ~/.docker/config since the beginning of DockSTARTer. As of today that has changed. For new installs the default DOCKERCONFDIR will be ~/.config/appdata instead of ~/.docker/config . For existing users nothing changes! You can keep your config folder right where it is. If you'd like to move your existing config to the new default location (even though you don't have to) you can do the following: Edit ~/. docker/compose/.env (in any text editor) and set DOCKERCONFDIR=~/.config/appdata And DOCKERSHAREDDIR=~/.config/appdata/shared If you're using duplicati you will also need to set DUPLICATI_BACKUPSDIR=~/.config/appdata/backups DUPLICATI_SOURCEDIR=~/.config/appdata (Unless you have these set somewhere else on purpose). Then run the following commands: ds -u ds -c down sudo mv ~/.docker/config ~/.config/appdata ds -c That's it! Your containers should fire right back up as if nothing has changed. If you have any issues feel free to ask for help in #ds-support","title":"Advanced Usage"},{"location":"advanced/advanced-usage/#advanced-usage","text":"Assuming you already followed the installation steps in the readme, there are also a number of command line switches you can use with DockSTARTer.","title":"Advanced Usage"},{"location":"advanced/advanced-usage/#command-line-switches","text":"","title":"Command Line Switches"},{"location":"advanced/advanced-usage/#run-the-install-script","text":"sudo ds -i This script does the following: Update your system using apt-get Install curl , git , grep , and sed (git should already be installed if you started with the install instructions on the main page, but it's here just in case) Install yq - by downloading the binary from source and installing it locally, used for piecing together YAML files Install docker - by downloading via the official docker-install script, used to run containers Install docker machine completion - by downloading the binary from source and installing it locally, provides tab completion for docker in bash shell (just a nice extra to have) Install docker-compose - using python3 pip, allows configuring of containers to be run together instead of individually running each one Install docker compose completion - by downloading the binary from source and installing it locally, provides tab completion for docker-compose in bash shell (just a nice extra to have) When the script finishes it will prompt you to reboot.","title":"Run The Install Script"},{"location":"advanced/advanced-usage/#run-the-compose-generator","text":"sudo ds -c This script verifies the dependencies above and installs or updates them as needed, then creates a file ~/.docker/compose/docker-compose.yml based on the variables you configured in your ~/.docker/compose/.env file. The generator script will prompt to run your selected containers after creating the file. We encourage you to have a look at the generated docker-compose.yml file, however if you wish to make changes please consider using overrides. Please review the Technical Info and Overrides pages. If you make any changes to your .env file (such as changing a port or enabling a new app) you need to rerun the generator which will rebuild only the affected containers.","title":"Run The Compose Generator"},{"location":"advanced/advanced-usage/#update-dockstarter","text":"sudo ds -u This should get you the latest changes to DockSTARTer. This will also backup and update your .env file. You may separately backup and update your .env file with the following command. sudo ds -e Then you may want to edit your .env file and run the generator again to bring up new apps or changes to existing apps.","title":"Update DockSTARTer"},{"location":"advanced/advanced-usage/#setup-your-environment","text":"If you do not yet have a ~/.docker/compose/.env file: sudo ds -e Edit the file using something like nano ~/.docker/compose/.env (ctrl+x will prompt to save and exit the nano editor)","title":"Setup Your Environment"},{"location":"advanced/advanced-usage/#universal-section","text":"You will need to fill out all of variables in the top most Universal section. You can find your PUID by running id -u ${USER} . You can find your PGID by running id -g ${USER} . Folders should be set to a location that actually exists even if you do not intend to use them (just make an empty folder and ignore it afterwards). Inside DOCKERCONFDIR , a folder for each app will be created for it's configuration. ${TZ} You should make sure your system's timezone is set correctly, and then also supply your timezone in the TZ variable (see List of tz database time zones ).","title":"Universal Section"},{"location":"advanced/advanced-usage/#application-variables","text":"","title":"Application Variables"},{"location":"advanced/advanced-usage/#adding-apps","text":"You can add the variables required to run an app by running: # sudo ds -a <APPNAME> ## Example: sudo ds -a sonarr Then your .env file fill have a variable named APPNAME_ENABLED that you can true and then run the Compose Generator to start the app. You may also need to fill in or adjust any other variables prefixed with the APPNAME_ that you're enabling. This is the best place to change your default ports. Please note, Portainer and Ouroboros are enabled by default. Portainer provides a snazzy management interface at your.ip.address:9000 and Ouroboros checks for updates to the Containers you are using, NOT DockSTARTer itself. See here for a (little) more or you can disable them if you wish.","title":"Adding Apps"},{"location":"advanced/advanced-usage/#removing-apps","text":"You can remove the variables for an app by running: # sudo ds -r <APPNAME> ## Example: sudo ds -r sonarr You can also remove all variables for all apps that are disabled by running: sudo ds -r You will be prompted individually for each app and shown what will be removed.","title":"Removing Apps"},{"location":"advanced/advanced-usage/#cleanup-unused-docker-resources","text":"sudo ds -p This cleans up the DS install, p stands for prune in this case. This recovers space from old images if they were somehow left over.","title":"Cleanup Unused Docker Resources"},{"location":"advanced/advanced-usage/#what-is-appdata","text":"If you've heard other people talk about an appdata folder and not been sure what they meant, it's what we have had as our default ~/.docker/config since the beginning of DockSTARTer. As of today that has changed. For new installs the default DOCKERCONFDIR will be ~/.config/appdata instead of ~/.docker/config . For existing users nothing changes! You can keep your config folder right where it is. If you'd like to move your existing config to the new default location (even though you don't have to) you can do the following: Edit ~/. docker/compose/.env (in any text editor) and set DOCKERCONFDIR=~/.config/appdata And DOCKERSHAREDDIR=~/.config/appdata/shared If you're using duplicati you will also need to set DUPLICATI_BACKUPSDIR=~/.config/appdata/backups DUPLICATI_SOURCEDIR=~/.config/appdata (Unless you have these set somewhere else on purpose). Then run the following commands: ds -u ds -c down sudo mv ~/.docker/config ~/.config/appdata ds -c That's it! Your containers should fire right back up as if nothing has changed. If you have any issues feel free to ask for help in #ds-support","title":"What Is appdata"},{"location":"advanced/backups/","text":"Backups Creating backups DockSTARTer menu has an option for Backup Config , or you can use one of sudo ds -b min / sudo ds -b med / sudo ds -b max to create backups. Min: Backs up your .env file Med: Backs up your .env file and the config folder for any enabled app Max: Backs up your .env file and any config folder found in your DOCKERCONFDIR. Apps will be stopped before running a backup and started after completing a backup. Med and Max also support pre/post commands in between each app (so you could disable uptime monitors for example) Min, Med, and Max support pre/post commands for the entire run. These commands can be set in .env Scheduling backups It is recommended to setup a cron job using sudo crontab -e and adding a line like 0 2 * * * /home/<USER>/.docker/main.sh -b min or 0 2 * * * /home/<USER>/.docker/main.sh -b med or 0 2 * * * /home/<USER>/.docker/main.sh -b max Which would make a daily backup at 2 AM. Backup retention The snapshot backup is created into ${BACKUP_CONFDIR}/<appname>.001 . If the folder <appname>.001 exists already it is rotated to <appname>.002 and so on, up to <appname>.512 by default (this can be adjusted), thereafter it is removed. So if you create one backup per night, for example with a cronjob, then this retention policy gives you 512 days of retention. This is useful but this can require to much disk space, that is why we have included a non-linear distribution policy. In short, we keep only the oldest backup in the range 257-512, and also in the range 129-256, and so on. This exponential distribution in time of the backups retains more backups in the short term and less in the long term; it keeps only 10 or 11 backups but spans a retention of 257-512 days. In the following table you can see on each column the different steps of the rotation, where each column shows the current set of snapshots (limited from .1 to .16 in this example): 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 6 6 6 6 7 7 7 7 8 8 8 8 8 9 9 10 10 11 11 12 12 13 13 14 14 15 15 16 16 16 To save more disk space, rsync will make hard links for each file of <appname>.001 that already existed in <appname>.002 with identical content, timestamps and ownerships. Deleting backups Backups created by DockSTARTer will be protected with a special attribute called immutable that makes the backups read only to all users including root. This is done to protect your backups from accidental deletion. Backups will be rotated through retention as described above because the backup script handles the immutable attribute. If you need to delete a backup manually you will first need to remove the immutable attribute from the folder using sudo chattr -R -i /path/to/backup/<appname>.### Credits The backup function is strongly borrowed from http://www.pointsoftware.ch/en/howto-local-and-remote-snapshot-backup-using-rsync-with-hard-links/ which has sections explaining how the rsync process works, including information about hard links (backups don't take up as much space as you think!)","title":"Backups"},{"location":"advanced/backups/#backups","text":"","title":"Backups"},{"location":"advanced/backups/#creating-backups","text":"DockSTARTer menu has an option for Backup Config , or you can use one of sudo ds -b min / sudo ds -b med / sudo ds -b max to create backups. Min: Backs up your .env file Med: Backs up your .env file and the config folder for any enabled app Max: Backs up your .env file and any config folder found in your DOCKERCONFDIR. Apps will be stopped before running a backup and started after completing a backup. Med and Max also support pre/post commands in between each app (so you could disable uptime monitors for example) Min, Med, and Max support pre/post commands for the entire run. These commands can be set in .env","title":"Creating backups"},{"location":"advanced/backups/#scheduling-backups","text":"It is recommended to setup a cron job using sudo crontab -e and adding a line like 0 2 * * * /home/<USER>/.docker/main.sh -b min or 0 2 * * * /home/<USER>/.docker/main.sh -b med or 0 2 * * * /home/<USER>/.docker/main.sh -b max Which would make a daily backup at 2 AM.","title":"Scheduling backups"},{"location":"advanced/backups/#backup-retention","text":"The snapshot backup is created into ${BACKUP_CONFDIR}/<appname>.001 . If the folder <appname>.001 exists already it is rotated to <appname>.002 and so on, up to <appname>.512 by default (this can be adjusted), thereafter it is removed. So if you create one backup per night, for example with a cronjob, then this retention policy gives you 512 days of retention. This is useful but this can require to much disk space, that is why we have included a non-linear distribution policy. In short, we keep only the oldest backup in the range 257-512, and also in the range 129-256, and so on. This exponential distribution in time of the backups retains more backups in the short term and less in the long term; it keeps only 10 or 11 backups but spans a retention of 257-512 days. In the following table you can see on each column the different steps of the rotation, where each column shows the current set of snapshots (limited from .1 to .16 in this example): 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 6 6 6 6 7 7 7 7 8 8 8 8 8 9 9 10 10 11 11 12 12 13 13 14 14 15 15 16 16 16 To save more disk space, rsync will make hard links for each file of <appname>.001 that already existed in <appname>.002 with identical content, timestamps and ownerships.","title":"Backup retention"},{"location":"advanced/backups/#deleting-backups","text":"Backups created by DockSTARTer will be protected with a special attribute called immutable that makes the backups read only to all users including root. This is done to protect your backups from accidental deletion. Backups will be rotated through retention as described above because the backup script handles the immutable attribute. If you need to delete a backup manually you will first need to remove the immutable attribute from the folder using sudo chattr -R -i /path/to/backup/<appname>.###","title":"Deleting backups"},{"location":"advanced/backups/#credits","text":"The backup function is strongly borrowed from http://www.pointsoftware.ch/en/howto-local-and-remote-snapshot-backup-using-rsync-with-hard-links/ which has sections explaining how the rsync process works, including information about hard links (backups don't take up as much space as you think!)","title":"Credits"},{"location":"advanced/domain-info/","text":"Domain Info Using ddclient with DDNS and Google Domains (and others) Info to come.","title":"Setting Up a Domain"},{"location":"advanced/domain-info/#domain-info","text":"","title":"Domain Info"},{"location":"advanced/domain-info/#using-ddclient-with-ddns-and-google-domains-and-others","text":"Info to come.","title":"Using ddclient with DDNS and Google Domains (and others)"},{"location":"advanced/macvlan/","text":"Macvlan Networking It may help to read the official documentation on Macvlan networks, as well as this tutorial which this page is based on. Motivation There are a few different types of Docker networks. DockSTARTer by default uses a 'bridge' network, which is a virtual network that provides isolation from other networks, but allows containers to communicate with each other. However, some applications require access to the physical network. Both Home Assistant and Plex need physical network access for discovery (the former will have issues communicating with IoT devices otherwise). One solution might be to use Docker's host network. This however, increases the odds of port conflicts as more containers are added. Docker introduced a Macvlan network for this case which assigns a unique IP and MAC address for attached containers. Setup On Your Router Take note of the IP address of your Docker host and create a DHCP reservation for the IP if there isn't one already. Configure DHCP so it will not assign address in a given range. That range will be occupied by our container's addresses. The rest of this tutorial assumes addresses above X.X.X.190 will be free. On Your Docker Host Create the macvlan network 1 : bash docker network create -d macvlan -o parent=<myinterface> --subnet X.X.X.0/24 --gateway X.X.X.1 --ip-range X.X.X.192/27 --aux-address 'host=X.X.X.Y' mymacvlan <myinterface> is the network interface your device is receiving data from. Run ifconfig for a listing of possible interfaces. Ex: eth0 subnet and gateway are specific to your LAN subnet ip-range is the range in which Docker will assign IP addresses. This example goes from X.X.X.192 to X.X.X.223 X.X.X.Y following host should be the IP address of your Docker host. Add the following to /etc/network/interfaces after replacing information as needed: bash # Create new macvlan interface on the host ip link add mymacvlanshim link myinterface type macvlan mode bridge # Add the host address and bring up the interface ip addr add X.X.X.Y/32 dev mymacvlanshim ip link set mymacvlanshim up # Tell our host to use that interface to communicate with containers ip route add 192.168.86.192/27 dev mymacvlanshim Reboot 1 You may be wondering why we don't create the network in Docker compose. Newer versions of compose have issues with using aux-address and ip-range . In Your DockSTARTer Overrides We could connect our containers to mymacvlan and call it a day, but it's very useful to reserve IPs for each container so we can reach web endpoints in a consistent way. Add something similar to this to your docker-compose.override.yml file for each container: yaml services: ouroboros: networks: composemacvlan: ipv4_address: X.X.X.201 networks: composemacvlan: external: name: mymacvlan version: \"3.4\" The ipv4 address should fall in the range you reserved. Unfortunately, it's necessary to do this when adding new containers if you want them on the same network. After this, you should be able to compose ( sudo ds -c ) and have a new shiny macvlan network! The containers will be available at the addresses you specified.","title":"Macvlan Networking"},{"location":"advanced/macvlan/#macvlan-networking","text":"It may help to read the official documentation on Macvlan networks, as well as this tutorial which this page is based on.","title":"Macvlan Networking"},{"location":"advanced/macvlan/#motivation","text":"There are a few different types of Docker networks. DockSTARTer by default uses a 'bridge' network, which is a virtual network that provides isolation from other networks, but allows containers to communicate with each other. However, some applications require access to the physical network. Both Home Assistant and Plex need physical network access for discovery (the former will have issues communicating with IoT devices otherwise). One solution might be to use Docker's host network. This however, increases the odds of port conflicts as more containers are added. Docker introduced a Macvlan network for this case which assigns a unique IP and MAC address for attached containers.","title":"Motivation"},{"location":"advanced/macvlan/#setup","text":"","title":"Setup"},{"location":"advanced/macvlan/#on-your-router","text":"Take note of the IP address of your Docker host and create a DHCP reservation for the IP if there isn't one already. Configure DHCP so it will not assign address in a given range. That range will be occupied by our container's addresses. The rest of this tutorial assumes addresses above X.X.X.190 will be free.","title":"On Your Router"},{"location":"advanced/macvlan/#on-your-docker-host","text":"Create the macvlan network 1 : bash docker network create -d macvlan -o parent=<myinterface> --subnet X.X.X.0/24 --gateway X.X.X.1 --ip-range X.X.X.192/27 --aux-address 'host=X.X.X.Y' mymacvlan <myinterface> is the network interface your device is receiving data from. Run ifconfig for a listing of possible interfaces. Ex: eth0 subnet and gateway are specific to your LAN subnet ip-range is the range in which Docker will assign IP addresses. This example goes from X.X.X.192 to X.X.X.223 X.X.X.Y following host should be the IP address of your Docker host. Add the following to /etc/network/interfaces after replacing information as needed: bash # Create new macvlan interface on the host ip link add mymacvlanshim link myinterface type macvlan mode bridge # Add the host address and bring up the interface ip addr add X.X.X.Y/32 dev mymacvlanshim ip link set mymacvlanshim up # Tell our host to use that interface to communicate with containers ip route add 192.168.86.192/27 dev mymacvlanshim Reboot 1 You may be wondering why we don't create the network in Docker compose. Newer versions of compose have issues with using aux-address and ip-range .","title":"On Your Docker Host"},{"location":"advanced/macvlan/#in-your-dockstarter-overrides","text":"We could connect our containers to mymacvlan and call it a day, but it's very useful to reserve IPs for each container so we can reach web endpoints in a consistent way. Add something similar to this to your docker-compose.override.yml file for each container: yaml services: ouroboros: networks: composemacvlan: ipv4_address: X.X.X.201 networks: composemacvlan: external: name: mymacvlan version: \"3.4\" The ipv4 address should fall in the range you reserved. Unfortunately, it's necessary to do this when adding new containers if you want them on the same network. After this, you should be able to compose ( sudo ds -c ) and have a new shiny macvlan network! The containers will be available at the addresses you specified.","title":"In Your DockSTARTer Overrides"},{"location":"advanced/overrides/","text":"Overrides The YML files included with and generated by DockSTARTer are NOT meant to be modified. Updating DockSTARTer will overwrite the YML files in ~/.docker/compose/.apps/ . The ~/.docker/compose/docker-compose.yml file is generated and rewritten by DockSTARTer when you use the Configuration menu or run sudo ds -c . If you would like to make some adjustments the best way is to use a docker-compose.override.yml file. Docker Compose will look for ~/.docker/compose/docker-compose.override.yml . Anything you set in this file will be merged in and take priority over the regular configurations. You can use this to modify existing apps (such as changing which image an app uses) or adding all the compose configurations needed to run an entirely new app that's not included in DockSTARTer. Example version: \"3.4\" # this must match the version in docker-compose.yml services: sonarr: image: hotio/sonarr volumes: - ${MEDIADIR_TV}:/media This will change Sonarr to use hotio's image for Sonarr and add a /media volume. Everything else from the original config such as the remaining volumes and environment variables will merge together. GoAccess: goaccess: image: gregyankovoy/goaccess hostname: stats.domain.com ports: - 7889:7889 volumes: - /etc/localtime:/etc/localtime:ro - /home/username/.docker/config/letsencrypt/log/nginx:/opt/log:ro - /home/username/.docker/config/goaccess:/config:rw container_name: goaccess","title":"Overrides"},{"location":"advanced/overrides/#overrides","text":"The YML files included with and generated by DockSTARTer are NOT meant to be modified. Updating DockSTARTer will overwrite the YML files in ~/.docker/compose/.apps/ . The ~/.docker/compose/docker-compose.yml file is generated and rewritten by DockSTARTer when you use the Configuration menu or run sudo ds -c . If you would like to make some adjustments the best way is to use a docker-compose.override.yml file. Docker Compose will look for ~/.docker/compose/docker-compose.override.yml . Anything you set in this file will be merged in and take priority over the regular configurations. You can use this to modify existing apps (such as changing which image an app uses) or adding all the compose configurations needed to run an entirely new app that's not included in DockSTARTer.","title":"Overrides"},{"location":"advanced/overrides/#example","text":"version: \"3.4\" # this must match the version in docker-compose.yml services: sonarr: image: hotio/sonarr volumes: - ${MEDIADIR_TV}:/media This will change Sonarr to use hotio's image for Sonarr and add a /media volume. Everything else from the original config such as the remaining volumes and environment variables will merge together. GoAccess: goaccess: image: gregyankovoy/goaccess hostname: stats.domain.com ports: - 7889:7889 volumes: - /etc/localtime:/etc/localtime:ro - /home/username/.docker/config/letsencrypt/log/nginx:/opt/log:ro - /home/username/.docker/config/goaccess:/config:rw container_name: goaccess","title":"Example"},{"location":"advanced/smb-mounting/","text":"SMB Mounting Linux Host Create a file called .credentials or the like in your home folder. In this folder, you're going to put this: username=<username to access resource> password=<password to access resource> substitute your own variables of course. From here, you're going to want to install cifs-utils: sudo apt-get install cifs-utils Then once that's done, you should be able to mount your SMB/Windows Share like so: sudo mount -t cifs //<host>/Downloads /mnt/downloads -o uid=1000,gid=1000,credentials=/home/<your home user>/.credentials,rw,vers=3.0 And to make sure that sticks, you're going to put this entry in your /etc/fstab file (You'll probably want to put it at the bottom) to match: //<host>/Downloads /mnt/downloads cifs uid=1000,gid=1000,credentials=/home/<your home user>/.credentials,rw,vers=3.0 You should be able to reboot to test the mount, but you should now be able to ls -al /mnt/Downloads (in my example) and see the files in your Shared Downloads folder! OpLock issues If you have containers that lock the drive and fail to unlock, you can deny the granting of opportunistic locks by setting the following registry entry: HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\mrxsmb HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\mrxsmb20 EnableOplocks REG_DWORD 0 Windows Host net use Z: \\\\host\\Downloads","title":"SMB Mounting"},{"location":"advanced/smb-mounting/#smb-mounting","text":"","title":"SMB Mounting"},{"location":"advanced/smb-mounting/#linux-host","text":"Create a file called .credentials or the like in your home folder. In this folder, you're going to put this: username=<username to access resource> password=<password to access resource> substitute your own variables of course. From here, you're going to want to install cifs-utils: sudo apt-get install cifs-utils Then once that's done, you should be able to mount your SMB/Windows Share like so: sudo mount -t cifs //<host>/Downloads /mnt/downloads -o uid=1000,gid=1000,credentials=/home/<your home user>/.credentials,rw,vers=3.0 And to make sure that sticks, you're going to put this entry in your /etc/fstab file (You'll probably want to put it at the bottom) to match: //<host>/Downloads /mnt/downloads cifs uid=1000,gid=1000,credentials=/home/<your home user>/.credentials,rw,vers=3.0 You should be able to reboot to test the mount, but you should now be able to ls -al /mnt/Downloads (in my example) and see the files in your Shared Downloads folder!","title":"Linux Host"},{"location":"advanced/smb-mounting/#oplock-issues","text":"If you have containers that lock the drive and fail to unlock, you can deny the granting of opportunistic locks by setting the following registry entry: HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\mrxsmb HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\mrxsmb20 EnableOplocks REG_DWORD 0","title":"OpLock issues"},{"location":"advanced/smb-mounting/#windows-host","text":"net use Z: \\\\host\\Downloads","title":"Windows Host"},{"location":"advanced/technical-info/","text":"Technical Info How Does DockSTARTer Work DockSTARTer works by generating the configuration that Compose uses. A linux \"pro\" might use Compose to do what DockSTARTer does themselves but it would still take a lot longer. Compose is a tool for defining and running multi-container Docker applications. To learn more about Compose refer to the following documentation . Compose works by reading YAML (*.yml) configuration files with the paths, ports and parameters each Container should run with. YML Files DO NOT EDIT THESE FILES DIRECTLY. Overriding these settings is easy but you must create a new file first. See the Overrides page. YML files are akin to XML files and below is an example: version: \"3.6\" services: sonarr: image: containers_author/sonarr container_name: sonarr restart: unless-stopped environment: - PGID=${PGID} - PUID=${PUID} - TZ=${TZ} volumes: - ${DOCKERCONFDIR}/sonarr:/config - ${DOWNLOADSDIR}:/downloads - ${MEDIADIR_TV}:/tv In the example above, image is the Container that you're using but also the quasi URL Docker will attempt to pull it from. container_name is the human readable name Docker will use to describe it. Volumes During the Getting Started section, you set volumes for your configuration, download and media etc in the GLOBAL section. The path to Sonarr's config in the above example, broken up, is ${DOCKERCONFDIR}/sonarr then the deliminator : followed by /config ${DOCKERCONFDIR}/sonarr is the path on your computer that Sonarr will see when it looks in /config . In this way, all your Containers will have their own private folder in your global config mount. The ${DOWNLOADSDIR} location is public to all apps that need it. That means Sonarr will be writing and reading from the same ${DOWNLOADSDIR}:/downloads mounts as Radarr, SickBeard etc AND your download clients. Here's mine! p2p@p2pmachine:/mnt/p2pDownloads$ ls -la total 13496 drwxr-xr-x 14 p2p p2p 4096 Jun 25 19:08 . drwxr-xr-x 6 root root 4096 Jun 23 16:20 .. drwxr-xr-x 3 p2p p2p 4096 Jun 24 08:26 complete drwxr-xr-x 5 p2p p2p 4096 Jun 30 08:31 completed drwxr-xr-x 2 p2p p2p 4096 Jun 24 08:26 incoming drwxr-xr-x 4 p2p p2p 4096 Jun 30 19:53 incomplete drwxr-xr-x 4 p2p p2p 4096 Jun 30 14:04 intermediate drwxr-xr-x 2 p2p p2p 16384 Jun 23 15:32 lost+found drwxr-xr-x 2 p2p p2p 4096 Jun 30 14:03 nzb -rw-r--r-- 1 p2p p2p 13726266 Jun 30 20:10 nzbget.log drwxr-xr-x 2 p2p p2p 20480 Jun 30 14:04 queue drwxr-xr-x 2 p2p p2p 4096 Jun 30 14:03 tmp drwxr-xr-x 7 p2p p2p 4096 Jun 30 19:53 transmission drwxr-xr-x 2 p2p p2p 4096 Jun 23 16:43 watch drwxr-xr-x 2 p2p p2p 4096 Jun 24 08:26 watched p2p@p2pmachine:/mnt/p2pDownloads$ The downside to this is that your root downloads location will start to look very messy if you have a lot of downloaders, with multiple complete and incomplete folders, some even being used by different download clients. Ineligant as that is, and a lot of those folders could be deleted, from unused testing etc, this is the default behavior because Sonarr and (for instance) Transmission need to refer to the same paths in order to seamlessly move files around. Sonarr and Radarr both support path mapping but having DS configure them is outside the scope of this project. Instead, if you want to run multiple download containers, configure Transmissions download directories itself (at ip.add.ress:9091/transmission/ ). Change them all to /downloads/transmission/incomplete , /downloads/transmission/complete etc etc. Then it has it's own folder but can still report the same root path. Again , do not edit the default YML files, instead, see the section on Overrides . (Assuming you are reading this page from start to finish for the first time) there is a reason you haven't seen their location yet ;) Ports The ports for access to (and from) your apps are manipulated in your .env ironment settings. I use the Sonarr example a lot but if you're not familiar, it's default port is 8989 . SONARR_PORT_8989=6969 If you were to edit the .env for sonarr to the above, and run the generator again, you would then access Sonarr at http://app.address:6969/calendar instead of the default port, 8989. Do not change your apps internal ports unless you know what you are doing. For instance, if you change Sonarr's internal port to 4545, it will still listen on 8989 by default. So then, you won't be able to access the WebGUI and without that, I don't even know where to begin changing the port in Sonarr's config files. And unless you want to run Transmission and RuTorrent side by side, I can't think of a good reason to change them in .env either.","title":"Technical Info"},{"location":"advanced/technical-info/#technical-info","text":"","title":"Technical Info"},{"location":"advanced/technical-info/#how-does-dockstarter-work","text":"DockSTARTer works by generating the configuration that Compose uses. A linux \"pro\" might use Compose to do what DockSTARTer does themselves but it would still take a lot longer. Compose is a tool for defining and running multi-container Docker applications. To learn more about Compose refer to the following documentation . Compose works by reading YAML (*.yml) configuration files with the paths, ports and parameters each Container should run with.","title":"How Does DockSTARTer Work"},{"location":"advanced/technical-info/#yml-files","text":"DO NOT EDIT THESE FILES DIRECTLY. Overriding these settings is easy but you must create a new file first. See the Overrides page. YML files are akin to XML files and below is an example: version: \"3.6\" services: sonarr: image: containers_author/sonarr container_name: sonarr restart: unless-stopped environment: - PGID=${PGID} - PUID=${PUID} - TZ=${TZ} volumes: - ${DOCKERCONFDIR}/sonarr:/config - ${DOWNLOADSDIR}:/downloads - ${MEDIADIR_TV}:/tv In the example above, image is the Container that you're using but also the quasi URL Docker will attempt to pull it from. container_name is the human readable name Docker will use to describe it.","title":"YML Files"},{"location":"advanced/technical-info/#volumes","text":"During the Getting Started section, you set volumes for your configuration, download and media etc in the GLOBAL section. The path to Sonarr's config in the above example, broken up, is ${DOCKERCONFDIR}/sonarr then the deliminator : followed by /config ${DOCKERCONFDIR}/sonarr is the path on your computer that Sonarr will see when it looks in /config . In this way, all your Containers will have their own private folder in your global config mount. The ${DOWNLOADSDIR} location is public to all apps that need it. That means Sonarr will be writing and reading from the same ${DOWNLOADSDIR}:/downloads mounts as Radarr, SickBeard etc AND your download clients. Here's mine! p2p@p2pmachine:/mnt/p2pDownloads$ ls -la total 13496 drwxr-xr-x 14 p2p p2p 4096 Jun 25 19:08 . drwxr-xr-x 6 root root 4096 Jun 23 16:20 .. drwxr-xr-x 3 p2p p2p 4096 Jun 24 08:26 complete drwxr-xr-x 5 p2p p2p 4096 Jun 30 08:31 completed drwxr-xr-x 2 p2p p2p 4096 Jun 24 08:26 incoming drwxr-xr-x 4 p2p p2p 4096 Jun 30 19:53 incomplete drwxr-xr-x 4 p2p p2p 4096 Jun 30 14:04 intermediate drwxr-xr-x 2 p2p p2p 16384 Jun 23 15:32 lost+found drwxr-xr-x 2 p2p p2p 4096 Jun 30 14:03 nzb -rw-r--r-- 1 p2p p2p 13726266 Jun 30 20:10 nzbget.log drwxr-xr-x 2 p2p p2p 20480 Jun 30 14:04 queue drwxr-xr-x 2 p2p p2p 4096 Jun 30 14:03 tmp drwxr-xr-x 7 p2p p2p 4096 Jun 30 19:53 transmission drwxr-xr-x 2 p2p p2p 4096 Jun 23 16:43 watch drwxr-xr-x 2 p2p p2p 4096 Jun 24 08:26 watched p2p@p2pmachine:/mnt/p2pDownloads$ The downside to this is that your root downloads location will start to look very messy if you have a lot of downloaders, with multiple complete and incomplete folders, some even being used by different download clients. Ineligant as that is, and a lot of those folders could be deleted, from unused testing etc, this is the default behavior because Sonarr and (for instance) Transmission need to refer to the same paths in order to seamlessly move files around. Sonarr and Radarr both support path mapping but having DS configure them is outside the scope of this project. Instead, if you want to run multiple download containers, configure Transmissions download directories itself (at ip.add.ress:9091/transmission/ ). Change them all to /downloads/transmission/incomplete , /downloads/transmission/complete etc etc. Then it has it's own folder but can still report the same root path. Again , do not edit the default YML files, instead, see the section on Overrides . (Assuming you are reading this page from start to finish for the first time) there is a reason you haven't seen their location yet ;)","title":"Volumes"},{"location":"advanced/technical-info/#ports","text":"The ports for access to (and from) your apps are manipulated in your .env ironment settings. I use the Sonarr example a lot but if you're not familiar, it's default port is 8989 . SONARR_PORT_8989=6969 If you were to edit the .env for sonarr to the above, and run the generator again, you would then access Sonarr at http://app.address:6969/calendar instead of the default port, 8989. Do not change your apps internal ports unless you know what you are doing. For instance, if you change Sonarr's internal port to 4545, it will still listen on 8989 by default. So then, you won't be able to access the WebGUI and without that, I don't even know where to begin changing the port in Sonarr's config files. And unless you want to run Transmission and RuTorrent side by side, I can't think of a good reason to change them in .env either.","title":"Ports"},{"location":"advanced/uninstall/","text":"Uninstalling Blurb from our Discord follows: ... you can remove everything in ~/.docker with exception to ~/.docker/config (which you may not have if your config is at ~/.config/appdata ). However, you may want to consider keeping the ~/.docker/compose/docker-compose.yml and ~/.docker/compose/.env to rebuild it using sudo docker-compose and pass the envs. ... you should see your containers in docker ps -a or GUI such as Portainer. DS installs everything by running docker compose the way docker recommends, so all DS is really doing is merging a compose file together for you. Once you have the compose file you can remove DS if you like. Also DS itself doesn't do anything on its own, so you could just leave it in place. Keep up with your .env file and your config folder and everything can be done using the official compose commands. Just save any configurations you decide you need to keep, and delete the ~/.docker folder. DockSTARTer installs docker using get.docker.com so you can read through that to > undo it if you decide you need to. Compose is installed through pip, so you can uninstall that through pip ( sudo pip uninstall docker-compose )","title":"Uninstall"},{"location":"advanced/uninstall/#uninstalling","text":"Blurb from our Discord follows: ... you can remove everything in ~/.docker with exception to ~/.docker/config (which you may not have if your config is at ~/.config/appdata ). However, you may want to consider keeping the ~/.docker/compose/docker-compose.yml and ~/.docker/compose/.env to rebuild it using sudo docker-compose and pass the envs. ... you should see your containers in docker ps -a or GUI such as Portainer. DS installs everything by running docker compose the way docker recommends, so all DS is really doing is merging a compose file together for you. Once you have the compose file you can remove DS if you like. Also DS itself doesn't do anything on its own, so you could just leave it in place. Keep up with your .env file and your config folder and everything can be done using the official compose commands. Just save any configurations you decide you need to keep, and delete the ~/.docker folder. DockSTARTer installs docker using get.docker.com so you can read through that to > undo it if you decide you need to. Compose is installed through pip, so you can uninstall that through pip ( sudo pip uninstall docker-compose )","title":"Uninstalling"},{"location":"advanced/vpn-info/","text":"VPNN Info VPN Services available to use through DockSTARTer VPN use is only available where we have found a easily configured container that runs as its own self contained unit. DelugeVPN qBittorrentVPN rTorrentVPN SABnzbdVPN TransmissionVPN VPN tun driver The VPN containers require an adjustment to your host system: echo \"iptable_mangle\" | sudo tee /etc/modules-load.d/iptable_mangle.conf echo \"tun\" | sudo tee /etc/modules-load.d/tun.conf sudo reboot Access VPN containers remotely using LetsEncrypt If you're attempting to access the Web UI for one of your VPN containers (e.g. TransmissionVPN, DelugeVPN, etc.) from outside of your home network using LetsEncrypt, you will need to modify the LetsEncrypt configuration file to support the name difference. The sample configs are controlled by LSIO , not by DockSTARTer. So this change is required to get the VPN containers running remotely. The sample proxy configuration files found in .docker/config/letsencrypt/nginx/proxy-confs/ will need to be modified and as usual, have the .sample removed from the filename. You will also need to edit the appropriate proxy .conf . The below example uses the TransmissionVPN container as an example: Enter either sudo nano transmission.subfolder.conf or sudo nano transmission.subdomain.conf depending on your configuration desires and change the below line: Original set $upstream_transmission transmission; Modified set $upstream_transmission transmissionvpn; Save the file out and then restart your containers with a ds -c command. How to check if the VPN is working https://torguard.net/checkmytorrentipaddress.php http://www.doileak.com/ http://ipmagnet.services.cbcdn.com/ http://test.torrentprivacy.com/ Use a VPN for everything If you require VPN on all connections it is recommended to install OpenVPN as you normally would ( in /etc/openvpn etc etc) and then have the Docker service started and stopped by the up / down scripts. You can disable auto starting of the containers by disabling the docker service. An example provided by a user in our community for Ubuntu: sudo systemctl disable docker vpnup.sh #!/bin/bash if [[ -L \"/sbin/init\" ]]; then systemctl start docker else /etc/init.d/docker start fi vpndown.sh #!/bin/bash if [[ -L \"/sbin/init\" ]]; then systemctl stop docker else /etc/init.d/docker stop fi If you make changes to your .env file you will need to run ds -c . If you stop the OpenVPN service, thereby stopping Docker, DockSTARTER might fail. Start your OpenVPN service and run ds -c again if it didn't work. PIA with Transmission For PIA VPN Configuration: These pages come in handy - https://github.com/haugene/docker-transmission-openvpn/blob/master/README.md#network-configuration-options If you run into slow VPN issues, it may be the container is using a default .ovpn config. So you'd use something like this in a Override : OPENVPN_CONFIG=UK Southampton depending on your region/location.","title":"VPN Information"},{"location":"advanced/vpn-info/#vpnn-info","text":"","title":"VPNN Info"},{"location":"advanced/vpn-info/#vpn-services-available-to-use-through-dockstarter","text":"VPN use is only available where we have found a easily configured container that runs as its own self contained unit. DelugeVPN qBittorrentVPN rTorrentVPN SABnzbdVPN TransmissionVPN","title":"VPN Services available to use through DockSTARTer"},{"location":"advanced/vpn-info/#vpn-tun-driver","text":"The VPN containers require an adjustment to your host system: echo \"iptable_mangle\" | sudo tee /etc/modules-load.d/iptable_mangle.conf echo \"tun\" | sudo tee /etc/modules-load.d/tun.conf sudo reboot","title":"VPN tun driver"},{"location":"advanced/vpn-info/#access-vpn-containers-remotely-using-letsencrypt","text":"If you're attempting to access the Web UI for one of your VPN containers (e.g. TransmissionVPN, DelugeVPN, etc.) from outside of your home network using LetsEncrypt, you will need to modify the LetsEncrypt configuration file to support the name difference. The sample configs are controlled by LSIO , not by DockSTARTer. So this change is required to get the VPN containers running remotely. The sample proxy configuration files found in .docker/config/letsencrypt/nginx/proxy-confs/ will need to be modified and as usual, have the .sample removed from the filename. You will also need to edit the appropriate proxy .conf . The below example uses the TransmissionVPN container as an example: Enter either sudo nano transmission.subfolder.conf or sudo nano transmission.subdomain.conf depending on your configuration desires and change the below line: Original set $upstream_transmission transmission; Modified set $upstream_transmission transmissionvpn; Save the file out and then restart your containers with a ds -c command.","title":"Access VPN containers remotely using LetsEncrypt"},{"location":"advanced/vpn-info/#how-to-check-if-the-vpn-is-working","text":"https://torguard.net/checkmytorrentipaddress.php http://www.doileak.com/ http://ipmagnet.services.cbcdn.com/ http://test.torrentprivacy.com/","title":"How to check if the VPN is working"},{"location":"advanced/vpn-info/#use-a-vpn-for-everything","text":"If you require VPN on all connections it is recommended to install OpenVPN as you normally would ( in /etc/openvpn etc etc) and then have the Docker service started and stopped by the up / down scripts. You can disable auto starting of the containers by disabling the docker service. An example provided by a user in our community for Ubuntu: sudo systemctl disable docker vpnup.sh #!/bin/bash if [[ -L \"/sbin/init\" ]]; then systemctl start docker else /etc/init.d/docker start fi vpndown.sh #!/bin/bash if [[ -L \"/sbin/init\" ]]; then systemctl stop docker else /etc/init.d/docker stop fi If you make changes to your .env file you will need to run ds -c . If you stop the OpenVPN service, thereby stopping Docker, DockSTARTER might fail. Start your OpenVPN service and run ds -c again if it didn't work.","title":"Use a VPN for everything"},{"location":"advanced/vpn-info/#pia-with-transmission","text":"For PIA VPN Configuration: These pages come in handy - https://github.com/haugene/docker-transmission-openvpn/blob/master/README.md#network-configuration-options If you run into slow VPN issues, it may be the container is using a default .ovpn config. So you'd use something like this in a Override : OPENVPN_CONFIG=UK Southampton depending on your region/location.","title":"PIA with Transmission"},{"location":"apps/airdcpp/","text":"AirDC++ AirDC++ is an easy to use client for Advanced Direct Connect and Direct Connect networks. You are able to join \"hubs\" with other users, and chat, perform searches and browse the share of each user. The GIT Repository for AirDC++ is located at https://github.com/gangefors/docker-airdcpp-webclient AirDC++ Install If you see the following error: No valid configuration found. Run the application with --configure parameter to set up initial configuration. Run the following commands to correct: docker stop airdcpp docker run --rm -it --volumes-from airdcpp gangefors/airdcpp-webclient --add-user You will be prompted to create a user and password, then run: docker start airdcpp","title":"AirdcPP"},{"location":"apps/airdcpp/#airdc","text":"AirDC++ is an easy to use client for Advanced Direct Connect and Direct Connect networks. You are able to join \"hubs\" with other users, and chat, perform searches and browse the share of each user. The GIT Repository for AirDC++ is located at https://github.com/gangefors/docker-airdcpp-webclient","title":"AirDC++"},{"location":"apps/airdcpp/#airdc-install","text":"If you see the following error: No valid configuration found. Run the application with --configure parameter to set up initial configuration. Run the following commands to correct: docker stop airdcpp docker run --rm -it --volumes-from airdcpp gangefors/airdcpp-webclient --add-user You will be prompted to create a user and password, then run: docker start airdcpp","title":"AirDC++ Install"},{"location":"apps/airsonic/","text":"Airsonic Airsonic is a free, web-based media streamer, providing ubiquitious access to your music. Use it to share your music with friends, or to listen to your own music while at work. You can stream to multiple players simultaneously, for instance to one player in your kitchen and another in your living room. The GIT Repository for Airsonic is located at https://github.com/linuxserver/docker-airsonic","title":"Airsonic"},{"location":"apps/airsonic/#airsonic","text":"Airsonic is a free, web-based media streamer, providing ubiquitious access to your music. Use it to share your music with friends, or to listen to your own music while at work. You can stream to multiple players simultaneously, for instance to one player in your kitchen and another in your living room. The GIT Repository for Airsonic is located at https://github.com/linuxserver/docker-airsonic","title":"Airsonic"},{"location":"apps/bazarr/","text":"Bazarr Bazarr is a companion application to Sonarr and Radarr. It can manage and download subtitles based on your requirements. You define your preferences by TV show or movie and Bazarr takes care of everything for you. The GIT Repository for Bazarr is located at https://github.com/linuxserver/docker-bazarr By default, the DockSTARTer configuration of Bazarr will map to the following volumes: - ${DOCKERSHAREDDIR}:/shared - ${MEDIADIR_MOVIES}:/movies - ${MEDIADIR_TV}:/tv If you have any media outside of those locations, you'll need to create an Override specifically for those volumes.","title":"Bazarr"},{"location":"apps/bazarr/#bazarr","text":"Bazarr is a companion application to Sonarr and Radarr. It can manage and download subtitles based on your requirements. You define your preferences by TV show or movie and Bazarr takes care of everything for you. The GIT Repository for Bazarr is located at https://github.com/linuxserver/docker-bazarr By default, the DockSTARTer configuration of Bazarr will map to the following volumes: - ${DOCKERSHAREDDIR}:/shared - ${MEDIADIR_MOVIES}:/movies - ${MEDIADIR_TV}:/tv If you have any media outside of those locations, you'll need to create an Override specifically for those volumes.","title":"Bazarr"},{"location":"apps/beets/","text":"Beets Beets is a music library manager and not, for the most part, a music player. It does include a simple player plugin and an experimental Web-based player, but it generally leaves actual sound-reproduction to specialized tools. The GIT Repository for Beets is located at https://github.com/linuxserver/docker-beets","title":"Beets"},{"location":"apps/beets/#beets","text":"Beets is a music library manager and not, for the most part, a music player. It does include a simple player plugin and an experimental Web-based player, but it generally leaves actual sound-reproduction to specialized tools. The GIT Repository for Beets is located at https://github.com/linuxserver/docker-beets","title":"Beets"},{"location":"apps/bitwarden/","text":"Bitwarden Bitwarden is a free and open-source password management service that stores sensitive information such as website credentials in an encrypted vault. This is a Bitwarden server API implementation written in Rust compatible with upstream Bitwarden clients , perfect for self-hosted deployment where running the official resource-heavy service might not be ideal. The GIT Repository for Bitwarden is located at https://github.com/dani-garcia/bitwarden_rs Bitwarden Install When installing the Bitwarden container, the installer will install under Appdata directory as the root user, however once it is installed you can change the owner/group of it to whatever is required Run the below command (from a terminal) to change the permissions if required. sudo chown -R owner:group ~/.config/appdata/bitwarden Having the owner group change will allow you to edit the files if required without running into permission issues.","title":"Bitwarden"},{"location":"apps/bitwarden/#bitwarden","text":"Bitwarden is a free and open-source password management service that stores sensitive information such as website credentials in an encrypted vault. This is a Bitwarden server API implementation written in Rust compatible with upstream Bitwarden clients , perfect for self-hosted deployment where running the official resource-heavy service might not be ideal. The GIT Repository for Bitwarden is located at https://github.com/dani-garcia/bitwarden_rs Bitwarden Install When installing the Bitwarden container, the installer will install under Appdata directory as the root user, however once it is installed you can change the owner/group of it to whatever is required Run the below command (from a terminal) to change the permissions if required. sudo chown -R owner:group ~/.config/appdata/bitwarden Having the owner group change will allow you to edit the files if required without running into permission issues.","title":"Bitwarden"},{"location":"apps/booksonic/","text":"Booksonic Booksonic is a server and an app for streaming your audiobooks to any pc or android phone. Most of the functionality is also availiable on other platforms that have apps for subsonic. The GIT Repository for Booksonic is located at https://github.com/linuxserver/docker-booksonic","title":"Booksonic"},{"location":"apps/booksonic/#booksonic","text":"Booksonic is a server and an app for streaming your audiobooks to any pc or android phone. Most of the functionality is also availiable on other platforms that have apps for subsonic. The GIT Repository for Booksonic is located at https://github.com/linuxserver/docker-booksonic","title":"Booksonic"},{"location":"apps/bookstack/","text":"BookStack BookStack is a free and open source Wiki designed for creating beautiful documentation. Feauturing a simple, but powerful WYSIWYG editor it allows for teams to create detailed and useful documentation with ease. Powered by SQL and including a Markdown editor for those who prefer it, BookStack is geared towards making documentation more of a pleasure than a chore. For more information on BookStack visit their website and check it out: https://www.bookstackapp.com The GIT Repository for BookStack is located at https://github.com/linuxserver/docker-bookstack","title":"BookStack"},{"location":"apps/bookstack/#bookstack","text":"BookStack is a free and open source Wiki designed for creating beautiful documentation. Feauturing a simple, but powerful WYSIWYG editor it allows for teams to create detailed and useful documentation with ease. Powered by SQL and including a Markdown editor for those who prefer it, BookStack is geared towards making documentation more of a pleasure than a chore. For more information on BookStack visit their website and check it out: https://www.bookstackapp.com The GIT Repository for BookStack is located at https://github.com/linuxserver/docker-bookstack","title":"BookStack"},{"location":"apps/calibreweb/","text":"Calibre-web Calibre-web is a web app providing a clean interface for browsing, reading and downloading eBooks using an existing Calibre database. It is also possible to integrate google drive and edit metadata and your calibre library through the app itself. The GIT Repository for Calibre-web is located at https://github.com/linuxserver/docker-calibre-web Calibre-web installation The Calibre-web docker is only a web front end to the actual Calibre application/database itself. You still need a Calibre metadata.db file for Calibre Web to function. To get this, you have to install Calibre somewhere and you can move the metadata.db file into either your /books or /shared folder.","title":"CalibreWeb"},{"location":"apps/calibreweb/#calibre-web","text":"Calibre-web is a web app providing a clean interface for browsing, reading and downloading eBooks using an existing Calibre database. It is also possible to integrate google drive and edit metadata and your calibre library through the app itself. The GIT Repository for Calibre-web is located at https://github.com/linuxserver/docker-calibre-web","title":"Calibre-web"},{"location":"apps/calibreweb/#calibre-web-installation","text":"The Calibre-web docker is only a web front end to the actual Calibre application/database itself. You still need a Calibre metadata.db file for Calibre Web to function. To get this, you have to install Calibre somewhere and you can move the metadata.db file into either your /books or /shared folder.","title":"Calibre-web installation"},{"location":"apps/cloudcmd/","text":"Cloud Commander Cloud Commander is a file manager for the web. It includes a command-line console and a text editor. Cloud Commander helps you manage your server and work with files, directories and programs in a web browser from any computer, mobile or tablet. The GIT Repository for Cloud Commander is located at https://github.com/coderaiser/cloudcmd","title":"CloudCMD"},{"location":"apps/cloudcmd/#cloud-commander","text":"Cloud Commander is a file manager for the web. It includes a command-line console and a text editor. Cloud Commander helps you manage your server and work with files, directories and programs in a web browser from any computer, mobile or tablet. The GIT Repository for Cloud Commander is located at https://github.com/coderaiser/cloudcmd","title":"Cloud Commander"},{"location":"apps/cloudflareddns/","text":"CloudFlareDDNS Update Frequency Every 5 minutes or when the container restarts. Source","title":"CloudFlareDDNS"},{"location":"apps/cloudflareddns/#cloudflareddns","text":"","title":"CloudFlareDDNS"},{"location":"apps/cloudflareddns/#update-frequency","text":"Every 5 minutes or when the container restarts. Source","title":"Update Frequency"},{"location":"apps/couchpotato/","text":"CouchPotato CouchPotato is an automatic NZB and torrent downloader. You can keep a movies I want list and it will search for NZBs/torrents of these movies every X hours. Once a movie is found, it will send it to SABnzbd or download the torrent to a specified directory. The GIT Repository for CouchPotato is located at https://github.com/linuxserver/docker-couchpotato .","title":"CouchPotato"},{"location":"apps/couchpotato/#couchpotato","text":"CouchPotato is an automatic NZB and torrent downloader. You can keep a movies I want list and it will search for NZBs/torrents of these movies every X hours. Once a movie is found, it will send it to SABnzbd or download the torrent to a specified directory. The GIT Repository for CouchPotato is located at https://github.com/linuxserver/docker-couchpotato .","title":"CouchPotato"},{"location":"apps/dasshio/","text":"dasshio [dasshio] is a Hass.io add-on to easily use Amazon Dash Buttons with Home Assistant The GIT Repository for dasshio is located at https://github.com/danimtb/dasshio .","title":"dasshio"},{"location":"apps/dasshio/#dasshio","text":"[dasshio] is a Hass.io add-on to easily use Amazon Dash Buttons with Home Assistant The GIT Repository for dasshio is located at https://github.com/danimtb/dasshio .","title":"dasshio"},{"location":"apps/ddclient/","text":"Ddclient DDclient is a Perl client used to update dynamic DNS entries for accounts on a Dynamic DNS Network Service Provider. It was originally written by Paul Burry and is now mostly by wimpunk. It has the capability to update more than just dyndns and it can fetch your WAN-ipaddress in a few different ways. The GIT Repository for Ddclient is located at https://github.com/linuxserver/docker-ddclient . Ddclient Install Edit the included config to uncomment this line: use=web, web=checkip.dyndns.org/, web-skip='IP Address' # found after IP Address Then find your service of choice in the file and fill out the info as described. CloudFlare is recommended.","title":"DDClient"},{"location":"apps/ddclient/#ddclient","text":"DDclient is a Perl client used to update dynamic DNS entries for accounts on a Dynamic DNS Network Service Provider. It was originally written by Paul Burry and is now mostly by wimpunk. It has the capability to update more than just dyndns and it can fetch your WAN-ipaddress in a few different ways. The GIT Repository for Ddclient is located at https://github.com/linuxserver/docker-ddclient .","title":"Ddclient"},{"location":"apps/ddclient/#ddclient-install","text":"Edit the included config to uncomment this line: use=web, web=checkip.dyndns.org/, web-skip='IP Address' # found after IP Address Then find your service of choice in the file and fill out the info as described. CloudFlare is recommended.","title":"Ddclient Install"},{"location":"apps/deluge/","text":"Deluge Deluge is a lightweight, Free Software, cross-platform BitTorrent client. The GIT Repository for Deluge is located at https://github.com/linuxserver/docker-deluge .","title":"Deluge"},{"location":"apps/deluge/#deluge","text":"Deluge is a lightweight, Free Software, cross-platform BitTorrent client. The GIT Repository for Deluge is located at https://github.com/linuxserver/docker-deluge .","title":"Deluge"},{"location":"apps/delugevpn/","text":"DelugeVPN DelugeVPN is a Docker build script for Arch Linux base with Deluge , Privoxy and OpenVPN all included in one image. The support forum for DelugeVPN is located at https://forums.unraid.net/topic/44109-support-binhex-delugevpn/ . The GIT Repository for DelugeVPN is located at https://github.com/binhex/arch-delugevpn . DelugeVPN WebUI Access If you're attempting to get access to the DelugeVPN WebUI remotely outside of your home network using LetsEncrypt you must follow the steps outlined in VPN Information .","title":"DelugeVPN"},{"location":"apps/delugevpn/#delugevpn","text":"DelugeVPN is a Docker build script for Arch Linux base with Deluge , Privoxy and OpenVPN all included in one image. The support forum for DelugeVPN is located at https://forums.unraid.net/topic/44109-support-binhex-delugevpn/ . The GIT Repository for DelugeVPN is located at https://github.com/binhex/arch-delugevpn .","title":"DelugeVPN"},{"location":"apps/delugevpn/#delugevpn-webui-access","text":"If you're attempting to get access to the DelugeVPN WebUI remotely outside of your home network using LetsEncrypt you must follow the steps outlined in VPN Information .","title":"DelugeVPN WebUI Access"},{"location":"apps/duckdns/","text":"DuckDNS DuckDNS is a free service which will point a DNS (sub domains of duckdns.org) to an IP of your choice. The service is completely free, and doesn't require reactivation or forum posts to maintain its existence. The GIT Repository for DuskDNS is located at https://github.com/linuxserver/docker-duckdns DuckDNS Install When installing the DuckDNS container, the you will be prompted for your subdomain and token as part of the variables setup. To get that token, you need to go to the duckdns website , register your subdomain(s) and retrieve your token. When the container creates and updates with your subdomain and token, it will then update your IP with the DuckDNS service every 5 minutes.","title":"DuckDNS"},{"location":"apps/duckdns/#duckdns","text":"DuckDNS is a free service which will point a DNS (sub domains of duckdns.org) to an IP of your choice. The service is completely free, and doesn't require reactivation or forum posts to maintain its existence. The GIT Repository for DuskDNS is located at https://github.com/linuxserver/docker-duckdns","title":"DuckDNS"},{"location":"apps/duckdns/#duckdns-install","text":"When installing the DuckDNS container, the you will be prompted for your subdomain and token as part of the variables setup. To get that token, you need to go to the duckdns website , register your subdomain(s) and retrieve your token. When the container creates and updates with your subdomain and token, it will then update your IP with the DuckDNS service every 5 minutes.","title":"DuckDNS Install"},{"location":"apps/duplicati/","text":"Duplicati Duplicati is a backup software solution to store encrypted backups online and works with standard protocols like FTP, SSH, WebDAV as well as popular services like Microsoft OneDrive, Amazon Cloud Drive & S3, Google Drive, box.com, Mega, hubiC and many others. The GIT Repository for Duplicati is located at https://github.com/linuxserver/docker-duplicati . Duplicati Installation If you install Duplicati, you may be wondering what the important folders and files are to backup in case something goes wrong and you want to restore and be back up and running within minutes. Everything regarding DockSTARTer is found in /source like below (You can exclude .git and .github):","title":"Duplicati"},{"location":"apps/duplicati/#duplicati","text":"Duplicati is a backup software solution to store encrypted backups online and works with standard protocols like FTP, SSH, WebDAV as well as popular services like Microsoft OneDrive, Amazon Cloud Drive & S3, Google Drive, box.com, Mega, hubiC and many others. The GIT Repository for Duplicati is located at https://github.com/linuxserver/docker-duplicati .","title":"Duplicati"},{"location":"apps/duplicati/#duplicati-installation","text":"If you install Duplicati, you may be wondering what the important folders and files are to backup in case something goes wrong and you want to restore and be back up and running within minutes. Everything regarding DockSTARTer is found in /source like below (You can exclude .git and .github):","title":"Duplicati Installation"},{"location":"apps/emby/","text":"Emby Emby organizes video, music, live TV, and photos from personal media libraries and streams them to smart TVs, streaming boxes and mobile devices. This container is packaged as a standalone emby Media Server. The GIT Repository for Emby is located at https://github.com/linuxserver/docker-emby .","title":"Emby"},{"location":"apps/emby/#emby","text":"Emby organizes video, music, live TV, and photos from personal media libraries and streams them to smart TVs, streaming boxes and mobile devices. This container is packaged as a standalone emby Media Server. The GIT Repository for Emby is located at https://github.com/linuxserver/docker-emby .","title":"Emby"},{"location":"apps/freshrss/","text":"FreshRSS FreshRSS is a free, self-hostable aggregator for rss feeds. The GIT Repository for FreshRSS is located at https://github.com/linuxserver/docker-freshrss .","title":"FreshRSS"},{"location":"apps/freshrss/#freshrss","text":"FreshRSS is a free, self-hostable aggregator for rss feeds. The GIT Repository for FreshRSS is located at https://github.com/linuxserver/docker-freshrss .","title":"FreshRSS"},{"location":"apps/glances/","text":"Placeholder page","title":"Glances"},{"location":"apps/grafana/","text":"Grafana Fix for permission problems If you see the following error: mkdir: cannot create directory '/var/lib/grafana/plugins': Permission denied, GF_PATHS_DATA='/var/lib/grafana' is not writable. Run the following command to fix it: sudo chown -R $USER:$USER ~/.config/appdata/grafana","title":"Grafana"},{"location":"apps/grafana/#grafana","text":"","title":"Grafana"},{"location":"apps/grafana/#fix-for-permission-problems","text":"If you see the following error: mkdir: cannot create directory '/var/lib/grafana/plugins': Permission denied, GF_PATHS_DATA='/var/lib/grafana' is not writable. Run the following command to fix it: sudo chown -R $USER:$USER ~/.config/appdata/grafana","title":"Fix for permission problems"},{"location":"apps/guacamole/","text":"Guacamole This guide will help you replicate Gilbn's tutorial to protect your Guacamole install with F2B Since DockSTARTer uses Oznu's image for Guacamole, it only generates logs inside the container itself. Following these steps will allow you to get the Guacamole container to generate a log file in ~/.config/appdata/guacamole which you can then mount to the LetsEncrypt container so F2B can monitor it and ban malicious IPs. You can find Gilbn's tutorial here . We recommend you read it over so you get a basic understanding of what you will be doing: Configuring Guacamole Create a logback.xml file inside ~/.config/appdata/guacamole/guacamole touch ~/.config/appdata/guacamole/guacamole/logback.xml or sudo nano ~/.config/appdata/guacamole/guacamole/logback.xml Open the file with your favorite editor and place the following contents inside of it: NOTE: Make sure to make changes to the timezone accordingly. Check the php-local.ini file in ~/.config/appdata/letsencrypt/php if you are not sure what your timezone is. <configuration> <!-- Appender for debugging --> <appender name=\"GUAC-DEBUG\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%d{HH:mm:ss.SSS, America/New_York} [%thread] %-5level %logger{36} - %msg%n</pattern> </encoder> </appender> <!-- Appender for debugging in a file--> <appender name=\"GUAC-DEBUG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>/config/logs/guacd.log</file> <encoder> <pattern>%d{HH:mm:ss.SSS, America/New_York} [%thread] %-5level %logger{36} - %msg%n</pattern> </encoder> </appender> <!-- Log at DEBUG level --> <root level=\"debug\"> <appender-ref ref=\"GUAC-DEBUG\"/> <appender-ref ref=\"GUAC-DEBUG_FILE\"/> </root> </configuration> Restart the Guacamole container so it creates guacd.log in ~/.config/appdata/guacamole/logs/ Modify your docker-compose.override.yml in ~/.docker/compose/docker-compose.override.yml file to mount the new log to letsencrypt Example: letsencrypt: volumes: - ${DOCKERCONFDIR}/guacamole/logs/:/var/log/guacamole/ **NOTE: From here on out, we will be using /var/log/guacamole to refer to where the guacd.log lives within letsencrypt. This is just an example, you can mount your log file wherever you want inside the letsencrypt container. Recreate your container by running ds -c up Perform an invalid login attempt on Guacamole Check the new guacd.log file located in ~/.config/appdata/guacamole/logs to verify the failed login attempt Example: grep -i nzbget ~/.config/appdata/guacamole/logs/guacd.log | grep failed 15:03:17.762 [http-nio-8080-exec-1] WARN o.a.g.r.auth.AuthenticationService - Authentication attempt from [x.x.x.x, x.x.x.x, x.x.x.x] for user \"nzbget\" failed. Configuring F2B Navigate to ~/.config/appdata/letsencrypt/fail2ban , in there you will see (2) folders action.d and filter.d , as well as other files, we are going to focus on the file called jail.local for now. Go ahead and open jail.local with your favorite editor as root and copy/paste the following: [guacamole-auth] enabled = true port = http,https filter = guacamole-auth logpath = /var/log/guacamole/guacd.log ignoreip = 192.168.1.0/24 **NOTE: The ignore IP is so that fail2ban won\u2019t ban your local IP. Check out https://www.aelius.com/njh/subnet_sheet.html if you are wondering what your CIDR notation is. Most often it will be /24 (netmask 255.255.255.0) To find your netmask run ipconfig /all on windows or ifconfig | grep netmask on linux. Next we are going to navigate to ~/.config/appdata/letsencrypt/fail2ban/filter.d and in there you will see a file called guacamole.conf . We can't use this file because the regex in there will not work for our purposes. Open guacamole.conf with your favorite text editor as root and modify the regex line called failregex to match this: \\bAuthentication attempt from <HOST> for user \"[^\"]*\" failed\\.$ Next save the file and name it guacamole-auth.conf Perform an invalid login attempt and check fail2ban's regex for Guacamole with the following command: docker exec -it letsencrypt fail2ban-regex /var/log/guacamole/guacd.log /config/fail2ban/filter.d/guacamole-auth.conf If you want to ban yourself, you can comment out the ignoreip line on jail.local . BONUS: Want to see notifications when someone gets the hammer? Check out this cool Discord guide or this Pushover guide Credits @halianelf, @christronyxyocum, @gilbN and @iXNyNe","title":"Guacamole"},{"location":"apps/guacamole/#guacamole","text":"This guide will help you replicate Gilbn's tutorial to protect your Guacamole install with F2B Since DockSTARTer uses Oznu's image for Guacamole, it only generates logs inside the container itself. Following these steps will allow you to get the Guacamole container to generate a log file in ~/.config/appdata/guacamole which you can then mount to the LetsEncrypt container so F2B can monitor it and ban malicious IPs. You can find Gilbn's tutorial here . We recommend you read it over so you get a basic understanding of what you will be doing:","title":"Guacamole"},{"location":"apps/guacamole/#configuring-guacamole","text":"Create a logback.xml file inside ~/.config/appdata/guacamole/guacamole touch ~/.config/appdata/guacamole/guacamole/logback.xml or sudo nano ~/.config/appdata/guacamole/guacamole/logback.xml Open the file with your favorite editor and place the following contents inside of it: NOTE: Make sure to make changes to the timezone accordingly. Check the php-local.ini file in ~/.config/appdata/letsencrypt/php if you are not sure what your timezone is. <configuration> <!-- Appender for debugging --> <appender name=\"GUAC-DEBUG\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%d{HH:mm:ss.SSS, America/New_York} [%thread] %-5level %logger{36} - %msg%n</pattern> </encoder> </appender> <!-- Appender for debugging in a file--> <appender name=\"GUAC-DEBUG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>/config/logs/guacd.log</file> <encoder> <pattern>%d{HH:mm:ss.SSS, America/New_York} [%thread] %-5level %logger{36} - %msg%n</pattern> </encoder> </appender> <!-- Log at DEBUG level --> <root level=\"debug\"> <appender-ref ref=\"GUAC-DEBUG\"/> <appender-ref ref=\"GUAC-DEBUG_FILE\"/> </root> </configuration> Restart the Guacamole container so it creates guacd.log in ~/.config/appdata/guacamole/logs/ Modify your docker-compose.override.yml in ~/.docker/compose/docker-compose.override.yml file to mount the new log to letsencrypt Example: letsencrypt: volumes: - ${DOCKERCONFDIR}/guacamole/logs/:/var/log/guacamole/ **NOTE: From here on out, we will be using /var/log/guacamole to refer to where the guacd.log lives within letsencrypt. This is just an example, you can mount your log file wherever you want inside the letsencrypt container. Recreate your container by running ds -c up Perform an invalid login attempt on Guacamole Check the new guacd.log file located in ~/.config/appdata/guacamole/logs to verify the failed login attempt Example: grep -i nzbget ~/.config/appdata/guacamole/logs/guacd.log | grep failed 15:03:17.762 [http-nio-8080-exec-1] WARN o.a.g.r.auth.AuthenticationService - Authentication attempt from [x.x.x.x, x.x.x.x, x.x.x.x] for user \"nzbget\" failed.","title":"Configuring Guacamole"},{"location":"apps/guacamole/#configuring-f2b","text":"Navigate to ~/.config/appdata/letsencrypt/fail2ban , in there you will see (2) folders action.d and filter.d , as well as other files, we are going to focus on the file called jail.local for now. Go ahead and open jail.local with your favorite editor as root and copy/paste the following: [guacamole-auth] enabled = true port = http,https filter = guacamole-auth logpath = /var/log/guacamole/guacd.log ignoreip = 192.168.1.0/24 **NOTE: The ignore IP is so that fail2ban won\u2019t ban your local IP. Check out https://www.aelius.com/njh/subnet_sheet.html if you are wondering what your CIDR notation is. Most often it will be /24 (netmask 255.255.255.0) To find your netmask run ipconfig /all on windows or ifconfig | grep netmask on linux. Next we are going to navigate to ~/.config/appdata/letsencrypt/fail2ban/filter.d and in there you will see a file called guacamole.conf . We can't use this file because the regex in there will not work for our purposes. Open guacamole.conf with your favorite text editor as root and modify the regex line called failregex to match this: \\bAuthentication attempt from <HOST> for user \"[^\"]*\" failed\\.$ Next save the file and name it guacamole-auth.conf Perform an invalid login attempt and check fail2ban's regex for Guacamole with the following command: docker exec -it letsencrypt fail2ban-regex /var/log/guacamole/guacd.log /config/fail2ban/filter.d/guacamole-auth.conf If you want to ban yourself, you can comment out the ignoreip line on jail.local . BONUS: Want to see notifications when someone gets the hammer? Check out this cool Discord guide or this Pushover guide Credits @halianelf, @christronyxyocum, @gilbN and @iXNyNe","title":"Configuring F2B"},{"location":"apps/h5ai/","text":"Placeholder page","title":"h5ai"},{"location":"apps/handbrake/","text":"Placeholder page","title":"HandBrake"},{"location":"apps/headphones/","text":"Placeholder page","title":"Headphones"},{"location":"apps/heimdall/","text":"Placeholder page","title":"Heimdall"},{"location":"apps/homeassistant/","text":"HomeAssistant Environment Variable You may want to override homeassistant with environment variable PYTHONWARNINGS=\"ignore:Unverified HTTPS request\" if you recevieve warning each 10 second for e.g. device tracking of self-signed Unifi Controller SSL certificated. Reference: https://community.home-assistant.io/t/endless-insecurerequestwarning-errors-with-unifi/31831/12","title":"HomeAssistant"},{"location":"apps/homeassistant/#homeassistant","text":"","title":"HomeAssistant"},{"location":"apps/homeassistant/#environment-variable","text":"You may want to override homeassistant with environment variable PYTHONWARNINGS=\"ignore:Unverified HTTPS request\" if you recevieve warning each 10 second for e.g. device tracking of self-signed Unifi Controller SSL certificated. Reference: https://community.home-assistant.io/t/endless-insecurerequestwarning-errors-with-unifi/31831/12","title":"Environment Variable"},{"location":"apps/htpcmanager/","text":"Placeholder page","title":"HTPCManager"},{"location":"apps/hydra2/","text":"Placeholder page","title":"Hydra2"},{"location":"apps/influxdb/","text":"Placeholder page","title":"InfluxDB"},{"location":"apps/jackett/","text":"Placeholder page for Jackett","title":"Jackett"},{"location":"apps/jellyfin/","text":"Placeholder page","title":"Jellyfin"},{"location":"apps/lazylibrarian/","text":"Placeholder page","title":"LazyLibrarian"},{"location":"apps/letsencrypt/","text":"LetsEncrypt LinuxServer's NGINX/LetsEncrypt Starter Guide If this is your first time learning about NGINX and LetsEncrypt, we highly recommend you read over their official guide, which can be found here General Setup Out of the box, the LetsEncrypt container created by linuxserver.io performs reverse proxy functions using NGINX and automatic https encrypted connections using certificates provided by LetsEncrypt . More on this container can be found here . To configure your reverse proxy, consider if you want to use subfolders (ie. domain.com/portainer) or subdomains (ie. portainer.domain.com). Subdomains will take more configuration, as DNS entries and certificate subject alternate names are required. The first thing to setup is your domain and email settings in .docker/compose/.env under LETSENCRYPT. Set the LETSENCRYPT_EMAIL and LETSENCRYPT_URL . If using subdomains ensure to add each subdomain to LETSENCRYPT_SUBDOMAINS as each subdomain prefix (ie. LETSENCRYPT_SUBDOMAINS=portainer,deluge,pihole . There are a number of sample proxy configuration files found in ~/.config/appdata/letsencrypt/nginx/proxy-confs/ and in most cases will just need the .sample removed from the filename. Currently not every applicable app has an example configuration and are still being tested. Subfolder Example: cp ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subfolder.conf.sample ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subfolder.conf This will make Portainer available at domain.com/portainer Subdomain Example: cp ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subdomain.conf.sample ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subdomain.conf and will enable the service at portainer.domain.com Each time you change a proxy conf file you will need to restart the LetsEncrypt container: docker restart letsencrypt Part 2 If you haven't forwarded ports for LE before container was setup, stop container, delete letsencrypt config folder, run ds -c , and you should be good to go. If you are not using subdomains: Blank out LETSENCRYPT_SUBDOMAINS in ~/.docker/compose/.env Like so: LETSENCRYPT_SUBDOMAINS= Fill in EMAIL, URL, like so: LETSENCRYPT_EMAIL=user@domain.com LETSENCRYPT_URL=appropriateaddress.com cp organizr.subfolder.conf.sample organizr.subfolder.conf in ~/.config/appdata/letsencrypt/nginx/proxy-confs Edit ~/.config/appdata/letsencrypt/nginx/site-confs/default and comment out the following (As shown): # location / { # try_files $uri $uri/ /index.html /index.php?$args =404; # } Ports In proxy_pass Generally speaking, your configuration does point to the port you specify, which is correct. DockSTARTer sets your app to 8080 on your internal network, but docker has a docker network as well. On that network your app runs on the default port for the app! That is how containers like LetsEncrypt and Organizr (For example) communicate. Redirect HTTP to HTTPS This change will make it so that if you type http://blahblah it will redirect to https://blahblah Edit ~/.config/appdata/nginx/site-confs/default Uncomment the relevant part of the file (see below) # listening on port 80 disabled by default, remove the \"#\" signs to enable # redirect all traffic to https server { listen 80; listen [::]:80; server_name _; return 301 https://$host$request_uri; } Restart the letsencrypt container docker restart letsencrypt","title":"LetsEncrypt"},{"location":"apps/letsencrypt/#letsencrypt","text":"","title":"LetsEncrypt"},{"location":"apps/letsencrypt/#linuxservers-nginxletsencrypt-starter-guide","text":"If this is your first time learning about NGINX and LetsEncrypt, we highly recommend you read over their official guide, which can be found here","title":"LinuxServer's NGINX/LetsEncrypt Starter Guide"},{"location":"apps/letsencrypt/#general-setup","text":"Out of the box, the LetsEncrypt container created by linuxserver.io performs reverse proxy functions using NGINX and automatic https encrypted connections using certificates provided by LetsEncrypt . More on this container can be found here . To configure your reverse proxy, consider if you want to use subfolders (ie. domain.com/portainer) or subdomains (ie. portainer.domain.com). Subdomains will take more configuration, as DNS entries and certificate subject alternate names are required. The first thing to setup is your domain and email settings in .docker/compose/.env under LETSENCRYPT. Set the LETSENCRYPT_EMAIL and LETSENCRYPT_URL . If using subdomains ensure to add each subdomain to LETSENCRYPT_SUBDOMAINS as each subdomain prefix (ie. LETSENCRYPT_SUBDOMAINS=portainer,deluge,pihole . There are a number of sample proxy configuration files found in ~/.config/appdata/letsencrypt/nginx/proxy-confs/ and in most cases will just need the .sample removed from the filename. Currently not every applicable app has an example configuration and are still being tested. Subfolder Example: cp ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subfolder.conf.sample ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subfolder.conf This will make Portainer available at domain.com/portainer Subdomain Example: cp ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subdomain.conf.sample ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subdomain.conf and will enable the service at portainer.domain.com Each time you change a proxy conf file you will need to restart the LetsEncrypt container: docker restart letsencrypt","title":"General Setup"},{"location":"apps/letsencrypt/#part-2","text":"If you haven't forwarded ports for LE before container was setup, stop container, delete letsencrypt config folder, run ds -c , and you should be good to go. If you are not using subdomains: Blank out LETSENCRYPT_SUBDOMAINS in ~/.docker/compose/.env Like so: LETSENCRYPT_SUBDOMAINS= Fill in EMAIL, URL, like so: LETSENCRYPT_EMAIL=user@domain.com LETSENCRYPT_URL=appropriateaddress.com cp organizr.subfolder.conf.sample organizr.subfolder.conf in ~/.config/appdata/letsencrypt/nginx/proxy-confs Edit ~/.config/appdata/letsencrypt/nginx/site-confs/default and comment out the following (As shown): # location / { # try_files $uri $uri/ /index.html /index.php?$args =404; # }","title":"Part 2"},{"location":"apps/letsencrypt/#ports-in-proxy_pass","text":"Generally speaking, your configuration does point to the port you specify, which is correct. DockSTARTer sets your app to 8080 on your internal network, but docker has a docker network as well. On that network your app runs on the default port for the app! That is how containers like LetsEncrypt and Organizr (For example) communicate.","title":"Ports In proxy_pass"},{"location":"apps/letsencrypt/#redirect-http-to-https","text":"This change will make it so that if you type http://blahblah it will redirect to https://blahblah Edit ~/.config/appdata/nginx/site-confs/default Uncomment the relevant part of the file (see below) # listening on port 80 disabled by default, remove the \"#\" signs to enable # redirect all traffic to https server { listen 80; listen [::]:80; server_name _; return 301 https://$host$request_uri; } Restart the letsencrypt container docker restart letsencrypt","title":"Redirect HTTP to HTTPS"},{"location":"apps/lidarr/","text":"Placeholder page","title":"Lidarr"},{"location":"apps/logarr/","text":"Logarr Logarr configuration has sharing to the logs enabled by default. From within the Logarr container, this is accessible via the /var/log/logarrlogs path. Which is mapped to your ~/.config/appdata path of your host machine. For Logarr you will need to edit the config.php file to point to the correct log files. This file is located in the ~/.config/appdata/logarr/www/logarr/assets/ folder of your host machine. Edit the included config to change these lines: \"Sonarr\" => '/var/log/logarrlogs/sonarr/logs/sonarr.txt', \"Radarr\" => '/var/log/logarrlogs/radarr/logs/radarr.txt',","title":"Logarr"},{"location":"apps/logarr/#logarr","text":"Logarr configuration has sharing to the logs enabled by default. From within the Logarr container, this is accessible via the /var/log/logarrlogs path. Which is mapped to your ~/.config/appdata path of your host machine. For Logarr you will need to edit the config.php file to point to the correct log files. This file is located in the ~/.config/appdata/logarr/www/logarr/assets/ folder of your host machine. Edit the included config to change these lines: \"Sonarr\" => '/var/log/logarrlogs/sonarr/logs/sonarr.txt', \"Radarr\" => '/var/log/logarrlogs/radarr/logs/radarr.txt',","title":"Logarr"},{"location":"apps/logitechmediaserver/","text":"Placeholder page","title":"LogitechMediaServer"},{"location":"apps/makemkv/","text":"Placeholder page","title":"MakeMKV"},{"location":"apps/mariadb/","text":"Placeholder page","title":"MariaDB"},{"location":"apps/mcmyadmin2/","text":"Placeholder page","title":"McMyAdmin2"},{"location":"apps/medusa/","text":"Placeholder page","title":"Medusa"},{"location":"apps/monitorr/","text":"Placeholder page","title":"Monitorr"},{"location":"apps/muximux/","text":"Placeholder page","title":"Muximux"},{"location":"apps/mylar/","text":"Placeholder page","title":"Mylar"},{"location":"apps/netdata/","text":"netdata By default, netdata will pull from a UID for the container itself to display in the list of netdata servers you have, so you would see something like '0f2342dac'. To define this and make it more readable/recognizable for you (In case you have multiple netdata servers): Stop the netdata container. Edit or Create this file: ~/.docker/compose/docker-compose.override.yml and change newnetdataname to friendlynamefornetdata . Once this is done, re-run sudo ds -c For Reverse Proxy configuration, we'll use this template from guys who already thought of this at organizrTools . Template from OrganizrTools Example: location = /netdata { return 301 /netdata/; } location ~ /netdata/(?<ndpath>.*) { include /config/nginx/proxy.conf; resolver 127.0.0.11 valid=30s; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass_request_headers on; proxy_set_header Connection \"keep-alive\"; proxy_store off; proxy_pass http://netdata:19999/$ndpath$is_args$args; proxy_headers_hash_max_size 512; proxy_headers_hash_bucket_size 64; gzip on; gzip_proxied any; gzip_types *; } Notifications Add health_alarm_notify.conf to your netdata config directory. Populate the notification service(s) you want with login, tokens or similar that is applicable. Instructions found in health_alarm_notify.conf . Create health.d directory in netdata config directory. Add conf files from health.d for which modules you want alarms. Also note that one can remove specific alarms by commenting them in .conf files. Get CPU temp from raspberry pi Netdata will not pick up cpu temp per default for raspberry pi. To activate chart for pi cpu temp add a file with name charts.d.conf in netdata config directory and add the following line. sensors=force Get data for home assistant To identify the correct data group and element to input in netdata home assistant component use http://yournetdataip:19999/api/v1/allmetrics?format=json Monitor services with netdata Create python.d directory in netdata config directory. Add httpcheck.conf to your python.d directory. Edit according to instructions in file, suggestion is to add after last line in conf file. See example below. # This plugin is intended for simple cases. Currently, the accuracy of the response time is low and should be used as reference only. Hydra: url: 'http://192.168.86.60:5076/nzbhydra/' timeout: 1 redirect: no status_accepted: - 200 regex: '.*hydra.*' Ombi: url: 'http://192.168.86.60:3579/ombi/landingpage' timeout: 1 redirect: yes status_accepted: - 200 regex: '.*ombi.*' You will now get charts in netdata for ombi and hydra. Please add your ip and ports accordingly. To get alarms add httpcheck.conf to your health.d directory. Don't forget to comment the unwanted alarms. Slow response alarm can be quite annoying. Netdata badges Coming soon.","title":"netdata"},{"location":"apps/netdata/#netdata","text":"By default, netdata will pull from a UID for the container itself to display in the list of netdata servers you have, so you would see something like '0f2342dac'. To define this and make it more readable/recognizable for you (In case you have multiple netdata servers): Stop the netdata container. Edit or Create this file: ~/.docker/compose/docker-compose.override.yml and change newnetdataname to friendlynamefornetdata . Once this is done, re-run sudo ds -c For Reverse Proxy configuration, we'll use this template from guys who already thought of this at organizrTools . Template from OrganizrTools Example: location = /netdata { return 301 /netdata/; } location ~ /netdata/(?<ndpath>.*) { include /config/nginx/proxy.conf; resolver 127.0.0.11 valid=30s; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass_request_headers on; proxy_set_header Connection \"keep-alive\"; proxy_store off; proxy_pass http://netdata:19999/$ndpath$is_args$args; proxy_headers_hash_max_size 512; proxy_headers_hash_bucket_size 64; gzip on; gzip_proxied any; gzip_types *; }","title":"netdata"},{"location":"apps/netdata/#notifications","text":"Add health_alarm_notify.conf to your netdata config directory. Populate the notification service(s) you want with login, tokens or similar that is applicable. Instructions found in health_alarm_notify.conf . Create health.d directory in netdata config directory. Add conf files from health.d for which modules you want alarms. Also note that one can remove specific alarms by commenting them in .conf files.","title":"Notifications"},{"location":"apps/netdata/#get-cpu-temp-from-raspberry-pi","text":"Netdata will not pick up cpu temp per default for raspberry pi. To activate chart for pi cpu temp add a file with name charts.d.conf in netdata config directory and add the following line. sensors=force","title":"Get CPU temp from raspberry pi"},{"location":"apps/netdata/#get-data-for-home-assistant","text":"To identify the correct data group and element to input in netdata home assistant component use http://yournetdataip:19999/api/v1/allmetrics?format=json","title":"Get data for home assistant"},{"location":"apps/netdata/#monitor-services-with-netdata","text":"Create python.d directory in netdata config directory. Add httpcheck.conf to your python.d directory. Edit according to instructions in file, suggestion is to add after last line in conf file. See example below. # This plugin is intended for simple cases. Currently, the accuracy of the response time is low and should be used as reference only. Hydra: url: 'http://192.168.86.60:5076/nzbhydra/' timeout: 1 redirect: no status_accepted: - 200 regex: '.*hydra.*' Ombi: url: 'http://192.168.86.60:3579/ombi/landingpage' timeout: 1 redirect: yes status_accepted: - 200 regex: '.*ombi.*' You will now get charts in netdata for ombi and hydra. Please add your ip and ports accordingly. To get alarms add httpcheck.conf to your health.d directory. Don't forget to comment the unwanted alarms. Slow response alarm can be quite annoying.","title":"Monitor services with netdata"},{"location":"apps/netdata/#netdata-badges","text":"Coming soon.","title":"Netdata badges"},{"location":"apps/nextcloud/","text":"NextCloud If you are running the DockSTARTer Nextcloud container behind a LetsEncrypt Reverse gateway, you may need to add a extra line to the NextCloud config.php file so it can find it. you will be able to access the web page all OK, but any apps may timeout or return an invalid password run the below command and add the line to the the config.php file before the ); nano /config/www/nextcloud/config/config.php 'overwritehost' => 'hostname', where your 'hostname' is the URL you use to access your NextCloud web interface, make sure you include the comma at the end. this will allow the apps to pass the username/password through to the application","title":"Nextcloud"},{"location":"apps/nextcloud/#nextcloud","text":"If you are running the DockSTARTer Nextcloud container behind a LetsEncrypt Reverse gateway, you may need to add a extra line to the NextCloud config.php file so it can find it. you will be able to access the web page all OK, but any apps may timeout or return an invalid password run the below command and add the line to the the config.php file before the ); nano /config/www/nextcloud/config/config.php 'overwritehost' => 'hostname', where your 'hostname' is the URL you use to access your NextCloud web interface, make sure you include the comma at the end. this will allow the apps to pass the username/password through to the application","title":"NextCloud"},{"location":"apps/nzbget/","text":"Placeholder page","title":"NZBGet"},{"location":"apps/nzbgetvpn/","text":"Placeholder page","title":"NZBGetVPN"},{"location":"apps/ombi/","text":"Placeholder page","title":"Ombi"},{"location":"apps/openvpnas/","text":"OpenVPNAS Information pulled from Docker Hub and edited for relevance. Setting up the application The admin interface is available at https://<ip>:943/admin with a default user/password of admin/password During first login, make sure that the \"Authentication\" in the webui is set to \"Local\" instead of \"PAM\". Then set up the user accounts with their password (user accounts created under PAM do not survive container update or recreation). The \"admin\" account is a system (PAM) account and after container update or recreation, its password reverts back to the default. It is highly recommended to block this user's access for security reasons: Set another user as an admin, Delete the \"admin\" user in the gui, Modify the as.conf file under config/etc and replace the line boot_pam_users.0=admin with #boot_pam_users.0=admin (this only has to be done once and will survive container recreation) Server Network Settings Make sure to change Hostname or IP Address to your public IP or public DNS name. It defaults to the docker internal IP. Also, and I think this goes without saying, make sure to forward the correct ports on your firewall to your host IP. LetsEncrypt Subdomain Config Sample LetsEncrypt Config Here","title":"OpenVPNAS"},{"location":"apps/openvpnas/#openvpnas","text":"Information pulled from Docker Hub and edited for relevance.","title":"OpenVPNAS"},{"location":"apps/openvpnas/#setting-up-the-application","text":"The admin interface is available at https://<ip>:943/admin with a default user/password of admin/password During first login, make sure that the \"Authentication\" in the webui is set to \"Local\" instead of \"PAM\". Then set up the user accounts with their password (user accounts created under PAM do not survive container update or recreation). The \"admin\" account is a system (PAM) account and after container update or recreation, its password reverts back to the default. It is highly recommended to block this user's access for security reasons: Set another user as an admin, Delete the \"admin\" user in the gui, Modify the as.conf file under config/etc and replace the line boot_pam_users.0=admin with #boot_pam_users.0=admin (this only has to be done once and will survive container recreation)","title":"Setting up the application"},{"location":"apps/openvpnas/#server-network-settings","text":"Make sure to change Hostname or IP Address to your public IP or public DNS name. It defaults to the docker internal IP. Also, and I think this goes without saying, make sure to forward the correct ports on your firewall to your host IP.","title":"Server Network Settings"},{"location":"apps/openvpnas/#letsencrypt-subdomain-config","text":"Sample LetsEncrypt Config Here","title":"LetsEncrypt Subdomain Config"},{"location":"apps/organizr/","text":"Placeholder page","title":"Organizr"},{"location":"apps/ouroboros/","text":"Full documentation can be found at the Ouroboros Wiki For information about update notifications see https://github.com/pyouroboros/ouroboros/wiki/Notifications","title":"Ouroboros"},{"location":"apps/phpmyadmin/","text":"Placeholder page","title":"phpMyAdmin"},{"location":"apps/pihole/","text":"PiHole Pi-hole takes over the local DNS service and may conflict with existing DNS services on your server. Ubuntu 18.04 currently uses systemd-resolv to server DNS and needs to be configured to either give up port 53 or be disabled. Netplan setup On Ubuntu 18.04 and newer you will have netplan controlling your network and should see https://netplan.io/ for examples on how to configure it. You need to set your nameserver to use your LAN's DNS or a public DNS such as 1.1.1.1 before proceeding with any instructions below. Resolvconf On Ubuntu 18.04, resolvconf was removed as the default means to control DNS. In addition to the settings mentioned regarding netplan, we recommend setting up resolvconf. To install run sudo apt install resolvconf Edit /etc/resolvconf/resolv.conf.d/head using sudo and enter nameserver 1.1.1.1 on the first uncommented line. Restart the service sudo service resolvconf restart Stop systemd-resolv from listening on port 53 Edit /etc/systemd/resolved.conf and set DNSStubListener=no (make sure it is not commented out with a # at the beginning of the line) and then run sudo systemctl restart systemd-resolved If that does not work you can try the following: Stop and disable systemd-resolv (only if the above does not work) sudo systemctl stop systemd-resolv.service sudo systemctl disable systemd-resolv.service Name resolution for localhost In most cases it might be required to set your localhost name in /etc/hosts 127.0.0.1 machinename.localhost machinename 127.0.0.1 domain.com","title":"PiHole"},{"location":"apps/pihole/#pihole","text":"Pi-hole takes over the local DNS service and may conflict with existing DNS services on your server. Ubuntu 18.04 currently uses systemd-resolv to server DNS and needs to be configured to either give up port 53 or be disabled.","title":"PiHole"},{"location":"apps/pihole/#netplan-setup","text":"On Ubuntu 18.04 and newer you will have netplan controlling your network and should see https://netplan.io/ for examples on how to configure it. You need to set your nameserver to use your LAN's DNS or a public DNS such as 1.1.1.1 before proceeding with any instructions below.","title":"Netplan setup"},{"location":"apps/pihole/#resolvconf","text":"On Ubuntu 18.04, resolvconf was removed as the default means to control DNS. In addition to the settings mentioned regarding netplan, we recommend setting up resolvconf. To install run sudo apt install resolvconf Edit /etc/resolvconf/resolv.conf.d/head using sudo and enter nameserver 1.1.1.1 on the first uncommented line. Restart the service sudo service resolvconf restart","title":"Resolvconf"},{"location":"apps/pihole/#stop-systemd-resolv-from-listening-on-port-53","text":"Edit /etc/systemd/resolved.conf and set DNSStubListener=no (make sure it is not commented out with a # at the beginning of the line) and then run sudo systemctl restart systemd-resolved If that does not work you can try the following:","title":"Stop systemd-resolv from listening on port 53"},{"location":"apps/pihole/#stop-and-disable-systemd-resolv-only-if-the-above-does-not-work","text":"sudo systemctl stop systemd-resolv.service sudo systemctl disable systemd-resolv.service","title":"Stop and disable systemd-resolv (only if the above does not work)"},{"location":"apps/pihole/#name-resolution-for-localhost","text":"In most cases it might be required to set your localhost name in /etc/hosts 127.0.0.1 machinename.localhost machinename 127.0.0.1 domain.com","title":"Name resolution for localhost"},{"location":"apps/plex/","text":"Plex Cannot Claim Server On First Run Upon starting up Plex for the first time, it's very likely you'll need to follow these steps: docker exec -it plex /bin/bash # download the script curl -L -o plex-claim-server.sh https://github.com/uglymagoo/plex-claim-server/raw/master/plex-claim-server.sh # make the script executable chmod +x plex-claim-server.sh # go to https://www.plex.tv/claim/ in your browser and get the claim token and replace PLEX_CLAIM with this token in the next command, please use use the double quotes around your claim token ./plex-claim-server.sh \"PLEX_CLAIM\" # fix permissions chown abc:abc \"/config/Library/Application Support/Plex Media Server/Preferences.xml\" # leave the container exit docker restart plex Alternatively if that doesn't work, try: Edit ~/.docker/compose/.env and set PLEX_NETWORK_MODE=host . After claiming your server set PLEX_NETWORK_MODE= (back to blank). How To Run Plex Pass Versions Edit ~/.docker/compose/.env and set: PLEX_VERSION=plexpass Then run ds -c Rebuilding From Scratch Thankfully, some of this information is well documented (but not easily found) over on Plex's website here! Moving an installation to another system: https://support.plex.tv/articles/201370363-move-an-install-to-another-system/ Where is the Plex Media Server data directory? https://support.plex.tv/articles/202915258-where-is-the-plex-media-server-data-directory-located/ Hardware Transcoding If you would like to have Plex use a GPU that is attached to your DockSTARTer host, you can do this using an override like so: plex: devices: - /dev/dri:/dev/dri Refer to this forum post for details: Using Hardware Acceleration in Docker","title":"Plex"},{"location":"apps/plex/#plex","text":"","title":"Plex"},{"location":"apps/plex/#cannot-claim-server-on-first-run","text":"Upon starting up Plex for the first time, it's very likely you'll need to follow these steps: docker exec -it plex /bin/bash # download the script curl -L -o plex-claim-server.sh https://github.com/uglymagoo/plex-claim-server/raw/master/plex-claim-server.sh # make the script executable chmod +x plex-claim-server.sh # go to https://www.plex.tv/claim/ in your browser and get the claim token and replace PLEX_CLAIM with this token in the next command, please use use the double quotes around your claim token ./plex-claim-server.sh \"PLEX_CLAIM\" # fix permissions chown abc:abc \"/config/Library/Application Support/Plex Media Server/Preferences.xml\" # leave the container exit docker restart plex Alternatively if that doesn't work, try: Edit ~/.docker/compose/.env and set PLEX_NETWORK_MODE=host . After claiming your server set PLEX_NETWORK_MODE= (back to blank).","title":"Cannot Claim Server On First Run"},{"location":"apps/plex/#how-to-run-plex-pass-versions","text":"Edit ~/.docker/compose/.env and set: PLEX_VERSION=plexpass Then run ds -c","title":"How To Run Plex Pass Versions"},{"location":"apps/plex/#rebuilding-from-scratch","text":"Thankfully, some of this information is well documented (but not easily found) over on Plex's website here! Moving an installation to another system: https://support.plex.tv/articles/201370363-move-an-install-to-another-system/ Where is the Plex Media Server data directory? https://support.plex.tv/articles/202915258-where-is-the-plex-media-server-data-directory-located/","title":"Rebuilding From Scratch"},{"location":"apps/plex/#hardware-transcoding","text":"If you would like to have Plex use a GPU that is attached to your DockSTARTer host, you can do this using an override like so: plex: devices: - /dev/dri:/dev/dri Refer to this forum post for details: Using Hardware Acceleration in Docker","title":"Hardware Transcoding"},{"location":"apps/plexrequests/","text":"Placeholder page","title":"PlexRequests"},{"location":"apps/portainer/","text":"To give Portainer the ability to go directly to your IP name of your server Log onto your Portainer server and then select Settings > Endpoints > your local endpoint (mine was primary) > and change \"Public IP\" it'll update those links to work put whatever IP you want to use in the link eg: 192.168.1.X","title":"Portainer"},{"location":"apps/portaineragent/","text":"Placeholder page","title":"PortainerAgent"},{"location":"apps/pyload/","text":"Placeholder page","title":"pyLoad"},{"location":"apps/qbittorrent/","text":"Placeholder page","title":"qBittorrent"},{"location":"apps/qbittorrentvpn/","text":"Placeholder page","title":"qBittorrentVPN"},{"location":"apps/quasselcore/","text":"Placeholder page","title":"QuasselCore"},{"location":"apps/quasselweb/","text":"Placeholder page","title":"QuasselWeb"},{"location":"apps/radarr/","text":"Placeholder page","title":"Radarr"},{"location":"apps/resiliosync/","text":"Placeholder page","title":"ResilioSync"},{"location":"apps/rtorrentvpn/","text":"Placeholder page","title":"rTorrentVPN"},{"location":"apps/rutorrent/","text":"Placeholder page","title":"ruTorrent"},{"location":"apps/sabnzbd/","text":"Placeholder page","title":"SABnzbd"},{"location":"apps/sabnzbdvpn/","text":"Placeholder page","title":"SABnzbdVPN"},{"location":"apps/samba/","text":"Samba Description Samba is using the SMB protocol to share Linux mounts, which then are accessible and mountable on e.g. a Windows computer. By default, Samba will share all media directories and Docker config directory over SMB on the host. These shares are protected with username ds and password ds . Access Shares Replace host with your DNS or IP-address of your Docker host. \\\\host\\DockSTARTer Related Mounting Windows share in Linux See SMB Mounting .","title":"Samba"},{"location":"apps/samba/#samba","text":"","title":"Samba"},{"location":"apps/samba/#description","text":"Samba is using the SMB protocol to share Linux mounts, which then are accessible and mountable on e.g. a Windows computer. By default, Samba will share all media directories and Docker config directory over SMB on the host. These shares are protected with username ds and password ds .","title":"Description"},{"location":"apps/samba/#access-shares","text":"Replace host with your DNS or IP-address of your Docker host. \\\\host\\DockSTARTer","title":"Access Shares"},{"location":"apps/samba/#related","text":"","title":"Related"},{"location":"apps/samba/#mounting-windows-share-in-linux","text":"See SMB Mounting .","title":"Mounting Windows share in Linux"},{"location":"apps/sickchill/","text":"Placeholder page","title":"SickChill"},{"location":"apps/sickrage/","text":"Placeholder page","title":"SiCKRAGE"},{"location":"apps/smokeping/","text":"Placeholder page","title":"SmokePing"},{"location":"apps/sonarr/","text":"Placeholder page","title":"Sonarr"},{"location":"apps/syncthing/","text":"Placeholder page","title":"Syncthing"},{"location":"apps/tautulli/","text":"Placeholder page","title":"Tautulli"},{"location":"apps/telegraf/","text":"Placeholder page","title":"Telegraf"},{"location":"apps/thelounge/","text":"Placeholder page","title":"TheLounge"},{"location":"apps/transmission/","text":"Placeholder page","title":"Transmission"},{"location":"apps/transmissionvpn/","text":"Placeholder page","title":"TransmissionVPN"},{"location":"apps/ttrss/","text":"Placeholder page","title":"TTRSS"},{"location":"apps/tvheadend/","text":"Placeholder page","title":"Tvheadend"},{"location":"apps/ubooquity/","text":"Placeholder page","title":"Ubooquity"},{"location":"apps/unifi/","text":"Placeholder page","title":"Unifi"},{"location":"apps/unificontroller/","text":"Placeholder page","title":"UnifiController"},{"location":"apps/varken/","text":"Placeholder page","title":"Varken"},{"location":"apps/vsftpd/","text":"Placeholder page","title":"vsftpd"},{"location":"apps/watchtower/","text":"Watchtower Notifications You can use an override for notifications to your favorite method (E-mail, Slack/Discord, MS Teams are supported in Watchtower currently): You would want to put this in your docker-compose.override.yml For Discord/Slack: watchtower: environment: - WATCHTOWER_NOTIFICATIONS=slack - WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL=https://url.discord.com/slack - WATCHTOWER_NOTIFICATION_SLACK_IDENTIFIER=watchtower-server-1 For E-Mail: watchtower: environment: - WATCHTOWER_NOTIFICATION_EMAIL_FROM=myemail@gmail.com - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD=secretPassword - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT=587 - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER=myemail@gmail.com - WATCHTOWER_NOTIFICATION_EMAIL_SERVER=smtp.gmail.com - WATCHTOWER_NOTIFICATION_EMAIL_TO=myemail@gmail.com - WATCHTOWER_NOTIFICATIONS=email This is what you could have had in your override previously : version: \"3.4\" # this must match the version in docker-compose.yml services: netdata: hostname: newhostname So now your override would look like this: version: \"3.4\" # this must match the version in docker-compose.yml services: netdata: hostname: newhostname watchtower: environment: - WATCHTOWER_NOTIFICATIONS=slack - WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL=https://url.discord.com/slack - WATCHTOWER_NOTIFICATION_SLACK_IDENTIFIER=watchtower-server-1","title":"Watchtower"},{"location":"apps/watchtower/#watchtower","text":"","title":"Watchtower"},{"location":"apps/watchtower/#notifications","text":"You can use an override for notifications to your favorite method (E-mail, Slack/Discord, MS Teams are supported in Watchtower currently): You would want to put this in your docker-compose.override.yml For Discord/Slack: watchtower: environment: - WATCHTOWER_NOTIFICATIONS=slack - WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL=https://url.discord.com/slack - WATCHTOWER_NOTIFICATION_SLACK_IDENTIFIER=watchtower-server-1 For E-Mail: watchtower: environment: - WATCHTOWER_NOTIFICATION_EMAIL_FROM=myemail@gmail.com - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD=secretPassword - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT=587 - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER=myemail@gmail.com - WATCHTOWER_NOTIFICATION_EMAIL_SERVER=smtp.gmail.com - WATCHTOWER_NOTIFICATION_EMAIL_TO=myemail@gmail.com - WATCHTOWER_NOTIFICATIONS=email This is what you could have had in your override previously : version: \"3.4\" # this must match the version in docker-compose.yml services: netdata: hostname: newhostname So now your override would look like this: version: \"3.4\" # this must match the version in docker-compose.yml services: netdata: hostname: newhostname watchtower: environment: - WATCHTOWER_NOTIFICATIONS=slack - WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL=https://url.discord.com/slack - WATCHTOWER_NOTIFICATION_SLACK_IDENTIFIER=watchtower-server-1","title":"Notifications"},{"location":"apps/znc/","text":"Placeholder page","title":"ZNC"},{"location":"basics/available-apps/","text":"Available Apps Please browse the repo here to see which apps are available: https://github.com/GhostWriters/DockSTARTer/tree/master/compose/.apps If an app folder exists then it is available for x86_64. Inside the folder will be files for ARMHF and AARCH64 if they are supported. If ARMHF is present but AARCH64 is not it will fall back to using ARMHF. You can see descriptions of each app in the GUI or in the main yml file for each app in the repository.","title":"Available Applications"},{"location":"basics/available-apps/#available-apps","text":"Please browse the repo here to see which apps are available: https://github.com/GhostWriters/DockSTARTer/tree/master/compose/.apps If an app folder exists then it is available for x86_64. Inside the folder will be files for ARMHF and AARCH64 if they are supported. If ARMHF is present but AARCH64 is not it will fall back to using ARMHF. You can see descriptions of each app in the GUI or in the main yml file for each app in the repository.","title":"Available Apps"},{"location":"basics/faq/","text":"FAQ Ouroboros And Portainer Enabled By Default These tools are extremely useful for people getting used to running docker. Their official documentation should explain why but you can disable either or both of them if you want. Ouroboros will monitor (all or specified) running docker containers and update them to the (latest or tagged) available image in the remote registry. Portainer allows you to manage your Docker stacks, containers, images, volumes, networks and more! It is compatible with the standalone Docker engine and with Docker Swarm. In short, Ouroboros keeps your Containers up to date and Portainer gives you a WebGUI for starting and stopping Containers. Have a look, at www.appropriateaddress.com:9000 . DockSTARTer previously enabled Watchtower by default before Ouroboros. The two do almost the same thing, but Ouroboros has more options. General troubleshooting help You can see the (quite helpful) logs of each container with a Quick action in Portainer: Reported Issues Creating network \"compose_default\" with the default driver ERROR: could not find an available, non-overlapping IPv4 address pool among the defaults to assign to the network This error can occur if your connected to a VPN while setting up the containers. Simply temporarily disconnect your VPN connection until the containers have been created and then reconnect again. Starting containers and getting the following or a similar error message: \"listen udp 0.0.0.0:5353: bind: address already in use\" As you could probably guess this means an application (most likely plex) is trying to use a port that is already in use. You can check which application it is with: sudo lsof -i :<myport> So in this example it would be: sudo lsof -i :5353 which will show you that Google Chrome is using the port you need. In this case you could just close Chrome, but there may be applications you need to uninstall for this to work properly.","title":"Frequently Asked Questions"},{"location":"basics/faq/#faq","text":"","title":"FAQ"},{"location":"basics/faq/#ouroboros-and-portainer-enabled-by-default","text":"These tools are extremely useful for people getting used to running docker. Their official documentation should explain why but you can disable either or both of them if you want. Ouroboros will monitor (all or specified) running docker containers and update them to the (latest or tagged) available image in the remote registry. Portainer allows you to manage your Docker stacks, containers, images, volumes, networks and more! It is compatible with the standalone Docker engine and with Docker Swarm. In short, Ouroboros keeps your Containers up to date and Portainer gives you a WebGUI for starting and stopping Containers. Have a look, at www.appropriateaddress.com:9000 . DockSTARTer previously enabled Watchtower by default before Ouroboros. The two do almost the same thing, but Ouroboros has more options.","title":"Ouroboros And Portainer Enabled By Default"},{"location":"basics/faq/#general-troubleshooting-help","text":"You can see the (quite helpful) logs of each container with a Quick action in Portainer:","title":"General troubleshooting help"},{"location":"basics/faq/#reported-issues","text":"","title":"Reported Issues"},{"location":"basics/faq/#creating-network-compose_default-with-the-default-driver-error-could-not-find-an-available-non-overlapping-ipv4-address-pool-among-the-defaults-to-assign-to-the-network","text":"This error can occur if your connected to a VPN while setting up the containers. Simply temporarily disconnect your VPN connection until the containers have been created and then reconnect again.","title":"Creating network \"compose_default\" with the default driver ERROR: could not find an available, non-overlapping IPv4 address pool among the defaults to assign to the network"},{"location":"basics/faq/#starting-containers-and-getting-the-following-or-a-similar-error-message-listen-udp-00005353-bind-address-already-in-use","text":"As you could probably guess this means an application (most likely plex) is trying to use a port that is already in use. You can check which application it is with: sudo lsof -i :<myport> So in this example it would be: sudo lsof -i :5353 which will show you that Google Chrome is using the port you need. In this case you could just close Chrome, but there may be applications you need to uninstall for this to work properly.","title":"Starting containers and getting the following or a similar error message: \"listen udp 0.0.0.0:5353: bind: address already in use\""},{"location":"basics/migration/","text":"Migration From local installs Stop the service for the existing app (so that ports are available) Start the app using DockSTARTer so that the config folder structure is created ( ~/.config/appdata/appname by default) Stop the app's docker container ( docker stop appname ) Locate the config of the local installation and copy it to ~/.config/appdata/appname (only grab the required files) Start the app ( sudo ds -c ) Inside the app's config, or settings web interface, adjust the folder locations that make use of files on the disk to match the docker volumes for the container Adjust the app config to communicate with other existing apps (both in and out of docker as needed) Optionally uninstall/remove original app and dependencies From other Docker containers Stop the app's old docker container Start the app using DockSTARTer so that the config folder structure is created ( ~/.config/appdata/appname by default) Stop the app's new docker container ( docker stop appname ) Locate the config of the old docker container and copy it to ~/.config/appdata/appname (only grab the required files) Start the app ( sudo ds -c ) Inside the app's config, or settings web interface, adjust the folder locations that make use of files on the disk to match the docker volumes for the new container Adjust the app config to communicate with other existing apps (both in and out of docker as needed) Remove the app's old docker container Example Sonarr's config is commonly found in ~/.config/NzbDrone . Following the instructions above, all files in ~/.config/NzbDrone would be copied to ~/.config/appdata/sonarr . After starting the new Sonarr in Docker, modify the Root Folder settings to tell Sonarr where your files are. DockSTARTer maps the true location of your media folders to locations the container expects to see such as /tv in the case of Sonarr, so that is where you will set your root folder. You will also need to modify your settings that have Sonarr connect to other apps such as Usenet or Torrent download clients. Rather than an IP address or localhost you would just use the name of the download client app, ex: nzbget as the hostname. The same would apply for any connections between any app.","title":"How to Migrate to DS"},{"location":"basics/migration/#migration","text":"","title":"Migration"},{"location":"basics/migration/#from-local-installs","text":"Stop the service for the existing app (so that ports are available) Start the app using DockSTARTer so that the config folder structure is created ( ~/.config/appdata/appname by default) Stop the app's docker container ( docker stop appname ) Locate the config of the local installation and copy it to ~/.config/appdata/appname (only grab the required files) Start the app ( sudo ds -c ) Inside the app's config, or settings web interface, adjust the folder locations that make use of files on the disk to match the docker volumes for the container Adjust the app config to communicate with other existing apps (both in and out of docker as needed) Optionally uninstall/remove original app and dependencies","title":"From local installs"},{"location":"basics/migration/#from-other-docker-containers","text":"Stop the app's old docker container Start the app using DockSTARTer so that the config folder structure is created ( ~/.config/appdata/appname by default) Stop the app's new docker container ( docker stop appname ) Locate the config of the old docker container and copy it to ~/.config/appdata/appname (only grab the required files) Start the app ( sudo ds -c ) Inside the app's config, or settings web interface, adjust the folder locations that make use of files on the disk to match the docker volumes for the new container Adjust the app config to communicate with other existing apps (both in and out of docker as needed) Remove the app's old docker container","title":"From other Docker containers"},{"location":"basics/migration/#example","text":"Sonarr's config is commonly found in ~/.config/NzbDrone . Following the instructions above, all files in ~/.config/NzbDrone would be copied to ~/.config/appdata/sonarr . After starting the new Sonarr in Docker, modify the Root Folder settings to tell Sonarr where your files are. DockSTARTer maps the true location of your media folders to locations the container expects to see such as /tv in the case of Sonarr, so that is where you will set your root folder. You will also need to modify your settings that have Sonarr connect to other apps such as Usenet or Torrent download clients. Rather than an IP address or localhost you would just use the name of the download client app, ex: nzbget as the hostname. The same would apply for any connections between any app.","title":"Example"},{"location":"basics/port-conflicts/","text":"Port Conflicts Issue/Problem During configuration the script exits with an error like the following: ERROR: for plex cannot start service plex: driver failed programming external connectivity on endpoint plex (5a4d78fd5ff6c4c1a978ef31): Error starting userland proxy: listen udp 0.0.0.0:5353: bind: address already in use ERROR: Encountered errors while bringing up the project. 2019-02-13 17:38:19 [FATAL] Docker Compose failed. This is due to another service that has occupied that port disallowing DockSTARTer from installing a service on that port. Troubleshooting Methods As DockSTARTer will check and fail if another service is occupying the port, it is necessary to locate and deal with the conflict. One way is to locate the service currently occupying the port. You can do the following: # sudo netstat -ltunp | grep -w ':<port>' ## Example: sudo netstat -ltunp | grep -w ':8080' Once you locate the offending service then you can choose what to do. Resolutions/Solutions Example: If you have avahi-daemon installed this will conflict with udp/5353 port usage for iTunes in Plex if selected. This will cause the script to exit with an [ERROR] and a [FATAL]. One resolution is to change the port being bound during configuration. During configuration change the external port exposed from 5353 to 5354 (or another unused port) . This will resolve the conflict. Another resolution would be to remove the software that is in conflict. Again as the example above. If you are not using mDNS resolution then avahi-daemon would be unnecessary. Simply remove the package with apt remove avahi-daemon from the base server. This will remove the offending service and allow the port to be used by the Docker service.","title":"Port Conflicts"},{"location":"basics/port-conflicts/#port-conflicts","text":"","title":"Port Conflicts"},{"location":"basics/port-conflicts/#issueproblem","text":"During configuration the script exits with an error like the following: ERROR: for plex cannot start service plex: driver failed programming external connectivity on endpoint plex (5a4d78fd5ff6c4c1a978ef31): Error starting userland proxy: listen udp 0.0.0.0:5353: bind: address already in use ERROR: Encountered errors while bringing up the project. 2019-02-13 17:38:19 [FATAL] Docker Compose failed. This is due to another service that has occupied that port disallowing DockSTARTer from installing a service on that port.","title":"Issue/Problem"},{"location":"basics/port-conflicts/#troubleshooting-methods","text":"As DockSTARTer will check and fail if another service is occupying the port, it is necessary to locate and deal with the conflict. One way is to locate the service currently occupying the port. You can do the following: # sudo netstat -ltunp | grep -w ':<port>' ## Example: sudo netstat -ltunp | grep -w ':8080' Once you locate the offending service then you can choose what to do.","title":"Troubleshooting Methods"},{"location":"basics/port-conflicts/#resolutionssolutions","text":"Example: If you have avahi-daemon installed this will conflict with udp/5353 port usage for iTunes in Plex if selected. This will cause the script to exit with an [ERROR] and a [FATAL]. One resolution is to change the port being bound during configuration. During configuration change the external port exposed from 5353 to 5354 (or another unused port) . This will resolve the conflict. Another resolution would be to remove the software that is in conflict. Again as the example above. If you are not using mDNS resolution then avahi-daemon would be unnecessary. Simply remove the package with apt remove avahi-daemon from the base server. This will remove the offending service and allow the port to be used by the Docker service.","title":"Resolutions/Solutions"}]}