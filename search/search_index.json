{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The main goal of DockSTARTer is to make it quick and easy to get up and running with Docker. You may choose to rely on DockSTARTer for various changes to your Docker system, or use DockSTARTer as a stepping stone and learn to do more advanced configurations. Getting Started One Time Setup (required) APT Systems (Debian/Ubuntu/Raspbian/etc) # NOTE: Ubuntu 18.10 is known to have issues with the installation process, 18.04 is recommended sudo apt-get install curl git bash -c \"$(curl -fsSL https://get.dockstarter.com)\" sudo reboot DNF Systems (Fedora) sudo dnf install curl git bash -c \"$(curl -fsSL https://get.dockstarter.com)\" sudo reboot YUM Systems (CentOS) sudo yum install curl git bash -c \"$(curl -fsSL https://get.dockstarter.com)\" sudo reboot Alternate install (any system) The standard install above downloads the initial script using a method with some known risks. For those concerned with the security of the above method here is an alternative: # NOTE: Run the appropriate command for your distro sudo apt-get install curl git sudo dnf install curl git sudo yum install curl git # NOTE: Do not sudo the next line. git clone https://github.com/GhostWriters/DockSTARTer \"/home/${USER}/.docker\" sudo bash /home/${USER}/.docker/main.sh -i sudo reboot Running DockSTARTer sudo ds To run DockSTARTer use the command above. You should now see the main menu from the screenshots. Select Configuration and then Full Setup and you will be guided through selecting apps and starting containers. See our documentation for more detailed information. Support Click the chat badge to join us on Discord for support! [ Feature Request ] [ Bug Report ] Contributors This project exists thanks to all the people who contribute. Backers Thank you to all our backers! [ Become a backer ] Sponsors Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [ Become a sponsor ] Support on Beerpay Support development with Beerpay ! Special Thanks SmartHomeBeginner.com for creating AtoMiC-ToolKit that served as this project's primary inspiration, and later this guide that provided some initial direction with Docker. LinuxServer.io for maintaining the majority of the Docker images used in this project.","title":"Home"},{"location":"#getting-started","text":"","title":"Getting Started"},{"location":"#one-time-setup-required","text":"APT Systems (Debian/Ubuntu/Raspbian/etc) # NOTE: Ubuntu 18.10 is known to have issues with the installation process, 18.04 is recommended sudo apt-get install curl git bash -c \"$(curl -fsSL https://get.dockstarter.com)\" sudo reboot DNF Systems (Fedora) sudo dnf install curl git bash -c \"$(curl -fsSL https://get.dockstarter.com)\" sudo reboot YUM Systems (CentOS) sudo yum install curl git bash -c \"$(curl -fsSL https://get.dockstarter.com)\" sudo reboot Alternate install (any system) The standard install above downloads the initial script using a method with some known risks. For those concerned with the security of the above method here is an alternative: # NOTE: Run the appropriate command for your distro sudo apt-get install curl git sudo dnf install curl git sudo yum install curl git # NOTE: Do not sudo the next line. git clone https://github.com/GhostWriters/DockSTARTer \"/home/${USER}/.docker\" sudo bash /home/${USER}/.docker/main.sh -i sudo reboot","title":"One Time Setup (required)"},{"location":"#running-dockstarter","text":"sudo ds To run DockSTARTer use the command above. You should now see the main menu from the screenshots. Select Configuration and then Full Setup and you will be guided through selecting apps and starting containers. See our documentation for more detailed information.","title":"Running DockSTARTer"},{"location":"#support","text":"Click the chat badge to join us on Discord for support! [ Feature Request ] [ Bug Report ]","title":"Support"},{"location":"#contributors","text":"This project exists thanks to all the people who contribute.","title":"Contributors"},{"location":"#backers","text":"Thank you to all our backers! [ Become a backer ]","title":"Backers"},{"location":"#sponsors","text":"Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [ Become a sponsor ]","title":"Sponsors"},{"location":"#support-on-beerpay","text":"Support development with Beerpay !","title":"Support on Beerpay"},{"location":"#special-thanks","text":"SmartHomeBeginner.com for creating AtoMiC-ToolKit that served as this project's primary inspiration, and later this guide that provided some initial direction with Docker. LinuxServer.io for maintaining the majority of the Docker images used in this project.","title":"Special Thanks"},{"location":"advanced/advanced-usage/","text":"Assuming you already followed the installation steps in the readme, there are also a number of command line switches you can use with DockSTARTer. Command Line Switches Run the docker install script sudo ds -i This script does the following: - Update your system using apt-get - Install curl , git , grep , and sed (git should already be installed if you started at the top of this guide, but it's here just in case) - Install yq - by downloading the binary from source and installing it locally, used for piecing together YAML files - Install docker - by downloading via the official docker-install script, used to run containers - Install docker machine completion - by downloading the binary from source and installing it locally, provides tab completion for docker in bash shell (just a nice extra to have) - Install docker-compose OR arm-compose - by downloading the binary from source and installing it locally, allows configuring of containers to be run together instead of individually running each one - Install docker compose completion - by downloading the binary from source and installing it locally, provides tab completion for docker-compose in bash shell (just a nice extra to have) When the script finishes it will prompt you to reboot. Run the generator sudo ds -c This script verifies the dependencies above and installs or updates them as needed, then creates a file ~/.docker/compose/docker-compose.yml based on the variables you configured in your .env file. The generator script will prompt to run your selected containers after creating the file. We encourage you to have a look at the generated docker-compose.yml file, however if you wish to make changes please consider using overrides. Please review the Technical Info and Overrides pages. If you make any changes to your .env file (such as changing a port or enabling a new app) you need to rerun the generator which will rebuild only the affected containers. To update DockSTARTer sudo ds -u This should get you the latest changes to DockSTARTer. Next you will want to ensure your .env file is updated as well: sudo ds -e Then you may want to edit your .env file and run the generator again to bring up new apps or changes to existing apps. Setup your environment If you do not yet have a ~/.docker/compose/.env file: cd ~/.docker/compose cp .env.example .env Edit the file using something like nano .env (ctrl+x will prompt to save and exit the nano editor) Universal Section You will need to fill out all of variables in the top most Universal section. You can find your PUID by running id -u ${USER} . You can find your PGID by running id -g ${USER} . Folders should be set to a location that actually exists even if you do not intend to use them (just make an empty folder and ignore it afterwards). Inside DOCKERCONFDIR , a folder for each app will be created for it's configuration. thanks to Patrick for letting us know! ${TZ} You should make sure your system's timezone is set correctly, and then also supply your timezone in the TZ variable (see List of tz database time zones ). Application Specific Section Navigate through the file and locate the APPNAME_ENABLED variables for the apps you wish to use and change their values from false to true . You may also need to fill in or adjust any other variables prefixed with the APPNAME_ that you're enabling. This is the best place to change your default ports. Please note, Portainer and Ouroboros are enabled by default. Portainer provides a snazzy management interface at your.ip.address:9000 and Ouroboros checks for updates to the Containers you are using, NOT DockSTARTer itself. See here for a (little) more or you can disable them if you wish. To clean up DockSTARTer any previous images at any time: sudo ds -p This cleans up the DS install, p stands for prune in this case. This recovers space from old images if they were somehow left over.","title":"Advanced Usage"},{"location":"advanced/advanced-usage/#command-line-switches","text":"","title":"Command Line Switches"},{"location":"advanced/advanced-usage/#run-the-docker-install-script","text":"sudo ds -i This script does the following: - Update your system using apt-get - Install curl , git , grep , and sed (git should already be installed if you started at the top of this guide, but it's here just in case) - Install yq - by downloading the binary from source and installing it locally, used for piecing together YAML files - Install docker - by downloading via the official docker-install script, used to run containers - Install docker machine completion - by downloading the binary from source and installing it locally, provides tab completion for docker in bash shell (just a nice extra to have) - Install docker-compose OR arm-compose - by downloading the binary from source and installing it locally, allows configuring of containers to be run together instead of individually running each one - Install docker compose completion - by downloading the binary from source and installing it locally, provides tab completion for docker-compose in bash shell (just a nice extra to have) When the script finishes it will prompt you to reboot.","title":"Run the docker install script"},{"location":"advanced/advanced-usage/#run-the-generator","text":"sudo ds -c This script verifies the dependencies above and installs or updates them as needed, then creates a file ~/.docker/compose/docker-compose.yml based on the variables you configured in your .env file. The generator script will prompt to run your selected containers after creating the file. We encourage you to have a look at the generated docker-compose.yml file, however if you wish to make changes please consider using overrides. Please review the Technical Info and Overrides pages. If you make any changes to your .env file (such as changing a port or enabling a new app) you need to rerun the generator which will rebuild only the affected containers.","title":"Run the generator"},{"location":"advanced/advanced-usage/#to-update-dockstarter","text":"sudo ds -u This should get you the latest changes to DockSTARTer. Next you will want to ensure your .env file is updated as well: sudo ds -e Then you may want to edit your .env file and run the generator again to bring up new apps or changes to existing apps.","title":"To update DockSTARTer"},{"location":"advanced/advanced-usage/#setup-your-environment","text":"If you do not yet have a ~/.docker/compose/.env file: cd ~/.docker/compose cp .env.example .env Edit the file using something like nano .env (ctrl+x will prompt to save and exit the nano editor)","title":"Setup your environment"},{"location":"advanced/advanced-usage/#universal-section","text":"You will need to fill out all of variables in the top most Universal section. You can find your PUID by running id -u ${USER} . You can find your PGID by running id -g ${USER} . Folders should be set to a location that actually exists even if you do not intend to use them (just make an empty folder and ignore it afterwards). Inside DOCKERCONFDIR , a folder for each app will be created for it's configuration. thanks to Patrick for letting us know! ${TZ} You should make sure your system's timezone is set correctly, and then also supply your timezone in the TZ variable (see List of tz database time zones ).","title":"Universal Section"},{"location":"advanced/advanced-usage/#application-specific-section","text":"Navigate through the file and locate the APPNAME_ENABLED variables for the apps you wish to use and change their values from false to true . You may also need to fill in or adjust any other variables prefixed with the APPNAME_ that you're enabling. This is the best place to change your default ports. Please note, Portainer and Ouroboros are enabled by default. Portainer provides a snazzy management interface at your.ip.address:9000 and Ouroboros checks for updates to the Containers you are using, NOT DockSTARTer itself. See here for a (little) more or you can disable them if you wish.","title":"Application Specific Section"},{"location":"advanced/advanced-usage/#to-clean-up-dockstarter-any-previous-images-at-any-time","text":"sudo ds -p This cleans up the DS install, p stands for prune in this case. This recovers space from old images if they were somehow left over.","title":"To clean up DockSTARTer any previous images at any time:"},{"location":"advanced/backups/","text":"Creating backups DockSTARTer menu has an option for Backup Config , or you can use one of sudo ds -b min / sudo ds -b med / sudo ds -b max to create backups. Min: Backs up your .env file Med: Backs up your .env file and the config folder for any enabled app Max: Backs up your .env file and any config folder found in your DOCKERCONFDIR. Apps will be stopped before running a backup and started after completing a backup. Med and Max also support pre/post commands in between each app (so you could disable uptime monitors for example) Min, Med, and Max support pre/post commands for the entire run. These commands can be set in .env Quote from our Discord server: Min only backs up .env (no need to stop anything) Med backs up enabled app configs without stopping containers. The biggest concern would be database files. The rest generally won't be locked. Max backs up each folder in your config folder even if there's no enabled app for that folder, and it stops each app before performing the backup and starts the app after the backup completes. Each app is only stopped during it's own backup and started before the next apps backup begins, and only started if it was running before the backup process started. So basically: Stop radarr Backup radarr Start radarr Stop sonarr Backup sonarr Start sonarr And if you had a config for an app you disabled it'll still backup that config but won't start the app after the backup (because the app wasn't running) Scheduling backups It is recommended to setup a cron job using sudo crontab -e and adding a line like 0 2 * * * /home/<USER>/.docker/main.sh -b min or 0 2 * * * /home/<USER>/.docker/main.sh -b med or 0 2 * * * /home/<USER>/.docker/main.sh -b max Which would make a daily backup at 2 AM. Backup retention The snapshot backup is created into ${BACKUP_CONFDIR}/<appname>.001 . If the folder <appname>.001 exists already it is rotated to <appname>.002 and so on, up to <appname>.512 by default (this can be adjusted), thereafter it is removed. So if you create one backup per night, for example with a cronjob, then this retention policy gives you 512 days of retention. This is useful but this can require to much disk space, that is why we have included a non-linear distribution policy. In short, we keep only the oldest backup in the range 257-512, and also in the range 129-256, and so on. This exponential distribution in time of the backups retains more backups in the short term and less in the long term; it keeps only 10 or 11 backups but spans a retention of 257-512 days. In the following table you can see on each column the different steps of the rotation, where each column shows the current set of snapshots (limited from .1 to .16 in this example): 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 6 6 6 6 7 7 7 7 8 8 8 8 8 9 9 10 10 11 11 12 12 13 13 14 14 15 15 16 16 16 To save more disk space, rsync will make hard links for each file of <appname>.001 that already existed in <appname>.002 with identical content, timestamps and ownerships. Deleting backups Backups created by DockSTARTer will be protected with a special attribute called immutable that makes the backups read only to all users including root. This is done to protect your backups from accidental deletion. Backups will be rotated through retention as described above because the backup script handles the immutable attribute. If you need to delete a backup manually you will first need to remove the immutable attribute from the folder using sudo chattr -R -i /path/to/backup/<appname>.### Credits The backup function is strongly borrowed from http://www.pointsoftware.ch/en/howto-local-and-remote-snapshot-backup-using-rsync-with-hard-links/ which has sections explaining how the rsync process works, including information about hard links (backups don't take up as much space as you think!)","title":"Backups"},{"location":"advanced/backups/#creating-backups","text":"DockSTARTer menu has an option for Backup Config , or you can use one of sudo ds -b min / sudo ds -b med / sudo ds -b max to create backups. Min: Backs up your .env file Med: Backs up your .env file and the config folder for any enabled app Max: Backs up your .env file and any config folder found in your DOCKERCONFDIR. Apps will be stopped before running a backup and started after completing a backup. Med and Max also support pre/post commands in between each app (so you could disable uptime monitors for example) Min, Med, and Max support pre/post commands for the entire run. These commands can be set in .env Quote from our Discord server: Min only backs up .env (no need to stop anything) Med backs up enabled app configs without stopping containers. The biggest concern would be database files. The rest generally won't be locked. Max backs up each folder in your config folder even if there's no enabled app for that folder, and it stops each app before performing the backup and starts the app after the backup completes. Each app is only stopped during it's own backup and started before the next apps backup begins, and only started if it was running before the backup process started. So basically: Stop radarr Backup radarr Start radarr Stop sonarr Backup sonarr Start sonarr And if you had a config for an app you disabled it'll still backup that config but won't start the app after the backup (because the app wasn't running)","title":"Creating backups"},{"location":"advanced/backups/#scheduling-backups","text":"It is recommended to setup a cron job using sudo crontab -e and adding a line like 0 2 * * * /home/<USER>/.docker/main.sh -b min or 0 2 * * * /home/<USER>/.docker/main.sh -b med or 0 2 * * * /home/<USER>/.docker/main.sh -b max Which would make a daily backup at 2 AM.","title":"Scheduling backups"},{"location":"advanced/backups/#backup-retention","text":"The snapshot backup is created into ${BACKUP_CONFDIR}/<appname>.001 . If the folder <appname>.001 exists already it is rotated to <appname>.002 and so on, up to <appname>.512 by default (this can be adjusted), thereafter it is removed. So if you create one backup per night, for example with a cronjob, then this retention policy gives you 512 days of retention. This is useful but this can require to much disk space, that is why we have included a non-linear distribution policy. In short, we keep only the oldest backup in the range 257-512, and also in the range 129-256, and so on. This exponential distribution in time of the backups retains more backups in the short term and less in the long term; it keeps only 10 or 11 backups but spans a retention of 257-512 days. In the following table you can see on each column the different steps of the rotation, where each column shows the current set of snapshots (limited from .1 to .16 in this example): 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 5 5 5 5 6 6 6 6 7 7 7 7 8 8 8 8 8 9 9 10 10 11 11 12 12 13 13 14 14 15 15 16 16 16 To save more disk space, rsync will make hard links for each file of <appname>.001 that already existed in <appname>.002 with identical content, timestamps and ownerships.","title":"Backup retention"},{"location":"advanced/backups/#deleting-backups","text":"Backups created by DockSTARTer will be protected with a special attribute called immutable that makes the backups read only to all users including root. This is done to protect your backups from accidental deletion. Backups will be rotated through retention as described above because the backup script handles the immutable attribute. If you need to delete a backup manually you will first need to remove the immutable attribute from the folder using sudo chattr -R -i /path/to/backup/<appname>.###","title":"Deleting backups"},{"location":"advanced/backups/#credits","text":"The backup function is strongly borrowed from http://www.pointsoftware.ch/en/howto-local-and-remote-snapshot-backup-using-rsync-with-hard-links/ which has sections explaining how the rsync process works, including information about hard links (backups don't take up as much space as you think!)","title":"Credits"},{"location":"advanced/domain-info/","text":"Using ddclient with DDNS and Google Domains (and others) Info to come.","title":"Setting Up a Domain"},{"location":"advanced/domain-info/#using-ddclient-with-ddns-and-google-domains-and-others","text":"Info to come.","title":"Using ddclient with DDNS and Google Domains (and others)"},{"location":"advanced/overrides/","text":"The YML files included with and generated by DockSTARTer are NOT meant to be modified. * Updating DockSTARTer will overwrite the YML files in ~/.docker/compose/.apps/ . * The ~/.docker/compose/docker-compose.yml file is generated and rewritten by DockSTARTer when you use the Configuration menu or run sudo ds -c . If you would like to make some adjustments the best way is to use a docker-compose.override.yml file. Docker Compose will look for ~/.docker/compose/docker-compose.override.yml . Anything you set in this file will be merged in and take priority over the regular configurations. You can use this to modify existing apps (such as changing which image an app uses) or adding all the compose configurations needed to run an entirely new app that's not included in DockSTARTer. Example: version: \"3.4\" # this must match the version in docker-compose.yml services: sonarr: image: hotio/suitarr:sonarr volumes: - ${MEDIADIR_TV}:/media This will change Sonarr to use hotio's suitarr image for Sonarr and add a /media volume. Everything else from the original config such as the remaining volumes and environment variables will merge together. GoAccess: goaccess: image: gregyankovoy/goaccess hostname: stats.domain.com ports: - 7889:7889 volumes: - /etc/localtime:/etc/localtime:ro - /home/username/.docker/config/letsencrypt/log/nginx:/opt/log:ro - /home/username/.docker/config/goaccess:/config:rw container_name: goaccess","title":"Overrides"},{"location":"advanced/overrides/#example","text":"version: \"3.4\" # this must match the version in docker-compose.yml services: sonarr: image: hotio/suitarr:sonarr volumes: - ${MEDIADIR_TV}:/media This will change Sonarr to use hotio's suitarr image for Sonarr and add a /media volume. Everything else from the original config such as the remaining volumes and environment variables will merge together. GoAccess: goaccess: image: gregyankovoy/goaccess hostname: stats.domain.com ports: - 7889:7889 volumes: - /etc/localtime:/etc/localtime:ro - /home/username/.docker/config/letsencrypt/log/nginx:/opt/log:ro - /home/username/.docker/config/goaccess:/config:rw container_name: goaccess","title":"Example:"},{"location":"advanced/smb-mounting/","text":"Linux Host Create a file called .credentials or the like in your home folder. In this folder, you're going to put this: username=<username to access resource> password=<password to access resource> substitute your own variables of course. From here, you're going to want to install cifs-utils: sudo apt-get install cifs-utils Then once that's done, you should be able to mount your SMB/Windows Share like so: sudo mount -t cifs //<host>/Downloads /mnt/downloads -o uid=1000,gid=1000,credentials=/home/<your home user>/.credentials,rw,vers=3.0 And to make sure that sticks, you're going to put this entry in your /etc/fstab file (You'll probably want to put it at the bottom) to match: //<host>/Downloads /mnt/downloads cifs uid=1000,gid=1000,credentials=/home/<your home user>/.mount-creds,rw,vers=3.0 You should be able to reboot to test the mount, but you should now be able to ls -al /mnt/Downloads (in my example) and see the files in your Shared Downloads folder! OpLock issues If you have containers that lock the drive and fail to unlock, you can deny the granting of opportunistic locks by setting the following registry entry: HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\mrxsmb HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\mrxsmb20 EnableOplocks REG_DWORD 0 Windows Host net use Z: \\\\host\\Downloads Related Start a Samba server See Samba .","title":"SMB Mounting"},{"location":"advanced/smb-mounting/#linux-host","text":"Create a file called .credentials or the like in your home folder. In this folder, you're going to put this: username=<username to access resource> password=<password to access resource> substitute your own variables of course. From here, you're going to want to install cifs-utils: sudo apt-get install cifs-utils Then once that's done, you should be able to mount your SMB/Windows Share like so: sudo mount -t cifs //<host>/Downloads /mnt/downloads -o uid=1000,gid=1000,credentials=/home/<your home user>/.credentials,rw,vers=3.0 And to make sure that sticks, you're going to put this entry in your /etc/fstab file (You'll probably want to put it at the bottom) to match: //<host>/Downloads /mnt/downloads cifs uid=1000,gid=1000,credentials=/home/<your home user>/.mount-creds,rw,vers=3.0 You should be able to reboot to test the mount, but you should now be able to ls -al /mnt/Downloads (in my example) and see the files in your Shared Downloads folder!","title":"Linux Host"},{"location":"advanced/smb-mounting/#oplock-issues","text":"If you have containers that lock the drive and fail to unlock, you can deny the granting of opportunistic locks by setting the following registry entry: HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\mrxsmb HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\mrxsmb20 EnableOplocks REG_DWORD 0","title":"OpLock issues"},{"location":"advanced/smb-mounting/#windows-host","text":"net use Z: \\\\host\\Downloads","title":"Windows Host"},{"location":"advanced/smb-mounting/#related","text":"","title":"Related"},{"location":"advanced/smb-mounting/#start-a-samba-server","text":"See Samba .","title":"Start a Samba server"},{"location":"advanced/technical-info/","text":"Advanced Settings Please note that much of the documentation below will not be necessary once the planned GUI is implemented. Also, this guide is meant to be generic, I mention app names interchangeable below. Until the GUI, this is meant to teach you enough about how things work to make some changes where you need to. How Does DockSTARTer Work? DockSTARTer works by generating the configuration that Compose uses. A linux \"pro\" might use Compose to do what DockSTARTer does themselves but it would still take a lot longer. Compose is a tool for defining and running multi-container Docker applications. To learn more about Compose refer to the following documentation . Compose works by reading YAML (*.yml) configuration files with the paths, ports and parameters each Container should run with. YML Files DO NOT EDIT THESE FILES DIRECTLY. Overriding these settings is easy but you must create a new file first. See the section, Overrides , below. YML files are akin to XML files and below is an example: version: \"3.6\" services: sonarr: image: containers_author/sonarr container_name: sonarr restart: always environment: - PGID=${PGID} - PUID=${PUID} - TZ=${TZ} volumes: - ${DOCKERCONFDIR}/sonarr:/config - ${DOWNLOADSDIR}:/downloads - ${MEDIADIR_TV}:/tv In the example above, image is the Container that you're using but also the quasi URL Docker will attempt to pull it from. container_name is the human readable name Docker will use to describe it. Volumes During the Getting Started section, you set volumes for your configuration, download and media etc in the GLOBAL section. The path to Sonarr's config in the above example, broken up, is ${DOCKERCONFDIR}/sonarr then the deliminator : followed by /config ${DOCKERCONFDIR}/sonarr is the path on your computer that Sonarr will see when it looks in /config . In this way, all your Containers will have their own private folder in your global config mount. The ${DOWNLOADSDIR} location is public to all apps that need it. That means Sonarr will be writing and reading from the same `${DOWNLOADSDIR}:/downloads' mounts as Radarr, SickBeard etc AND your download clients. Here's mine! p2p@p2pmachine:/mnt/p2pDownloads$ ls -la total 13496 drwxr-xr-x 14 p2p p2p 4096 Jun 25 19:08 . drwxr-xr-x 6 root root 4096 Jun 23 16:20 .. drwxr-xr-x 3 p2p p2p 4096 Jun 24 08:26 complete drwxr-xr-x 5 p2p p2p 4096 Jun 30 08:31 completed drwxr-xr-x 2 p2p p2p 4096 Jun 24 08:26 incoming drwxr-xr-x 4 p2p p2p 4096 Jun 30 19:53 incomplete drwxr-xr-x 4 p2p p2p 4096 Jun 30 14:04 intermediate drwxr-xr-x 2 p2p p2p 16384 Jun 23 15:32 lost+found drwxr-xr-x 2 p2p p2p 4096 Jun 30 14:03 nzb -rw-r--r-- 1 p2p p2p 13726266 Jun 30 20:10 nzbget.log drwxr-xr-x 2 p2p p2p 20480 Jun 30 14:04 queue drwxr-xr-x 2 p2p p2p 4096 Jun 30 14:03 tmp drwxr-xr-x 7 p2p p2p 4096 Jun 30 19:53 transmission drwxr-xr-x 2 p2p p2p 4096 Jun 23 16:43 watch drwxr-xr-x 2 p2p p2p 4096 Jun 24 08:26 watched p2p@p2pmachine:/mnt/p2pDownloads$ The downside to this is that your root downloads location will start to look very messy if you have a lot of downloaders, with multiple complete and incomplete folders, some even being used by different download clients. Ineligant as that is, and a lot of those folders could be deleted, from unused testing etc, this is the default behavior because Sonarr and (for instance) Transmission need to refer to the same paths in order to seamlessly move files around. Sonarr and Radarr both support path mapping but having DS configure them is outside the scope of this project. Instead, if you want to run multiple download containers, configure Transmissions download directories itself (at ip.add.ress:9091/transmission/ ). Change them all to /downloads/transmission/incomplete , /downloads/transmission/complete etc etc. Then it has it's own folder but can still report the same root path. Again , do not edit the default YML files, instead, see the section on Overrides . (Assuming you are reading this page from start to finish for the first time) there is a reason you haven't seen their location yet ;) Ports The ports for access to (and from) your apps are manipulated in your .env ironment settings. I use the Sonarr example a lot but if you're not familiar, it's default port is 8989 . SONARR_PORT_8989=6969 If you were to edit the .env for sonarr to the above, and run the generator again, you would then access Sonarr at http://app.address:6969/calendar instead of the default port, 8989. Do not change your apps internal ports unless you know what you are doing. For instance, if you change Sonarr's internal port to 4545, it will still listen on 8989 by default. So then, you won't be able to access the WebGUI and without that, I don't even know where to begin changing the port in Sonarr's config files. And unless you want to run Transmission and RuTorrent side by side, I can't think of a good reason to change them in .env either.","title":"Technical Info"},{"location":"advanced/technical-info/#advanced-settings","text":"Please note that much of the documentation below will not be necessary once the planned GUI is implemented. Also, this guide is meant to be generic, I mention app names interchangeable below. Until the GUI, this is meant to teach you enough about how things work to make some changes where you need to.","title":"Advanced Settings"},{"location":"advanced/technical-info/#how-does-dockstarter-work","text":"DockSTARTer works by generating the configuration that Compose uses. A linux \"pro\" might use Compose to do what DockSTARTer does themselves but it would still take a lot longer. Compose is a tool for defining and running multi-container Docker applications. To learn more about Compose refer to the following documentation . Compose works by reading YAML (*.yml) configuration files with the paths, ports and parameters each Container should run with.","title":"How Does DockSTARTer Work?"},{"location":"advanced/technical-info/#yml-files","text":"DO NOT EDIT THESE FILES DIRECTLY. Overriding these settings is easy but you must create a new file first. See the section, Overrides , below. YML files are akin to XML files and below is an example: version: \"3.6\" services: sonarr: image: containers_author/sonarr container_name: sonarr restart: always environment: - PGID=${PGID} - PUID=${PUID} - TZ=${TZ} volumes: - ${DOCKERCONFDIR}/sonarr:/config - ${DOWNLOADSDIR}:/downloads - ${MEDIADIR_TV}:/tv In the example above, image is the Container that you're using but also the quasi URL Docker will attempt to pull it from. container_name is the human readable name Docker will use to describe it.","title":"YML Files"},{"location":"advanced/technical-info/#volumes","text":"During the Getting Started section, you set volumes for your configuration, download and media etc in the GLOBAL section. The path to Sonarr's config in the above example, broken up, is ${DOCKERCONFDIR}/sonarr then the deliminator : followed by /config ${DOCKERCONFDIR}/sonarr is the path on your computer that Sonarr will see when it looks in /config . In this way, all your Containers will have their own private folder in your global config mount. The ${DOWNLOADSDIR} location is public to all apps that need it. That means Sonarr will be writing and reading from the same `${DOWNLOADSDIR}:/downloads' mounts as Radarr, SickBeard etc AND your download clients. Here's mine! p2p@p2pmachine:/mnt/p2pDownloads$ ls -la total 13496 drwxr-xr-x 14 p2p p2p 4096 Jun 25 19:08 . drwxr-xr-x 6 root root 4096 Jun 23 16:20 .. drwxr-xr-x 3 p2p p2p 4096 Jun 24 08:26 complete drwxr-xr-x 5 p2p p2p 4096 Jun 30 08:31 completed drwxr-xr-x 2 p2p p2p 4096 Jun 24 08:26 incoming drwxr-xr-x 4 p2p p2p 4096 Jun 30 19:53 incomplete drwxr-xr-x 4 p2p p2p 4096 Jun 30 14:04 intermediate drwxr-xr-x 2 p2p p2p 16384 Jun 23 15:32 lost+found drwxr-xr-x 2 p2p p2p 4096 Jun 30 14:03 nzb -rw-r--r-- 1 p2p p2p 13726266 Jun 30 20:10 nzbget.log drwxr-xr-x 2 p2p p2p 20480 Jun 30 14:04 queue drwxr-xr-x 2 p2p p2p 4096 Jun 30 14:03 tmp drwxr-xr-x 7 p2p p2p 4096 Jun 30 19:53 transmission drwxr-xr-x 2 p2p p2p 4096 Jun 23 16:43 watch drwxr-xr-x 2 p2p p2p 4096 Jun 24 08:26 watched p2p@p2pmachine:/mnt/p2pDownloads$ The downside to this is that your root downloads location will start to look very messy if you have a lot of downloaders, with multiple complete and incomplete folders, some even being used by different download clients. Ineligant as that is, and a lot of those folders could be deleted, from unused testing etc, this is the default behavior because Sonarr and (for instance) Transmission need to refer to the same paths in order to seamlessly move files around. Sonarr and Radarr both support path mapping but having DS configure them is outside the scope of this project. Instead, if you want to run multiple download containers, configure Transmissions download directories itself (at ip.add.ress:9091/transmission/ ). Change them all to /downloads/transmission/incomplete , /downloads/transmission/complete etc etc. Then it has it's own folder but can still report the same root path. Again , do not edit the default YML files, instead, see the section on Overrides . (Assuming you are reading this page from start to finish for the first time) there is a reason you haven't seen their location yet ;)","title":"Volumes"},{"location":"advanced/technical-info/#ports","text":"The ports for access to (and from) your apps are manipulated in your .env ironment settings. I use the Sonarr example a lot but if you're not familiar, it's default port is 8989 . SONARR_PORT_8989=6969 If you were to edit the .env for sonarr to the above, and run the generator again, you would then access Sonarr at http://app.address:6969/calendar instead of the default port, 8989. Do not change your apps internal ports unless you know what you are doing. For instance, if you change Sonarr's internal port to 4545, it will still listen on 8989 by default. So then, you won't be able to access the WebGUI and without that, I don't even know where to begin changing the port in Sonarr's config files. And unless you want to run Transmission and RuTorrent side by side, I can't think of a good reason to change them in .env either.","title":"Ports"},{"location":"advanced/uninstall/","text":"Blurb from our Discord follows: It's already \"normal\" in the sense that you can remove more or less everything in ~/.docker with exception to ~/.docker/config (which you may not have if your config is at ~/.config/appdata ). However, you may want to consider keeping the ~/.docker/compose/docker-compose.yml and ~/.docker/compose/.env to rebuild it using sudo docker-compose and pass the envs. Otherwise, you should see your running/created containers in docker ps or GUI such as Portainer. You want to keep those specific files and folders and then you can delete everything else. DS installs everything by running docker compose the way docker recommends, so all DS is really doing is merging a compose file together for you. Once you have the compose file you can remove DS if you like. Also DS itself doesn't do anything on its own, so you could just leave it in place. Keep up with your .env file and your config folder and everything can be done using the official compose commands. Just save any configurations you decide you need to keep, and delete the ~/.docker folder. DockSTARTer installs docker using get.docker.com so you can read through that to undo it if you decide you need to. Compose is installed through pip, so you can uninstall that through pip ( sudo pip uninstall docker-compose )","title":"Uninstall"},{"location":"advanced/vpn-info/","text":"What VPN Services are available to use through DockSTARTer? At the moment VPN is only available where we have found a easily configured container that runs as its own self contained unit. TransmissionVPN, SabNzbDVPN, DelugeVPN & rTorrentVPN are currently available. VPN tun driver The VPN containers require an adjustment to your host system: echo \"iptable_mangle\" | sudo tee /etc/modules-load.d/iptable_mangle.conf echo \"tun\" | sudo tee /etc/modules-load.d/tun.conf sudo reboot Access VPN containers remotely using LetsEncrypt If you're attempting to access the Web UI for one of your VPN containers (e.g. TransmissionVPN, DelugeVPN, etc.) from outside of your home network using LetsEncrypt, you will need to modify the LetsEncrypt configuration file to support the name difference. The sample configs are controlled by LSIO , not by DockSTARTer. So this change is required to get the VPN containers running remotely. The sample proxy configuration files found in .docker/config/letsencrypt/nginx/proxy-confs/ will need to be modified and as usual, have the .sample removed from the filename. You will also need to edit the appropriate proxy .conf . The below example uses the TransmissionVPN container as an example: Enter either sudo nano transmission.subfolder.conf or sudo nano transmission.subdomain.conf depending on your configuration desires and change the below line: Original set $upstream_transmission transmission; Modified set $upstream_transmission transmissionvpn; Save the file out and then restart your containers with a ds -c command. How can I check if my VPN is working? https://torguard.net/checkmytorrentipaddress.php http://www.doileak.com/ http://ipmagnet.services.cbcdn.com/ http://test.torrentprivacy.com/ What if I want to use a VPN for everything ? If you require VPN on all connections it is recommended to install OpenVPN as you normally would ( in /etc/openvpn etc etc) and then having the Docker service started and stopped by the up / down scripts. You can disable auto starting of the containers by disabling the docker service. On Ubuntu, I used sudo systemctl disable docker My vpnup.sh consists of #!/bin/bash if [[ -L \"/sbin/init\" ]]; then systemctl start docker else /etc/init.d/docker start fi and Down - #!/bin/bash if [[ -L \"/sbin/init\" ]]; then systemctl stop docker else /etc/init.d/docker stop fi If you make changes to the .env file, you will need to run the generator again. If you stop the OpenVPN service, thereby stopping Docker, the generation might not work. Start your OpenVPN service and run the generation again if it didn't work. cd ~/.docker/compose sudo ds -c PIA with Transmission For PIA VPN Configuration: These pages come in handy - * https://github.com/haugene/docker-transmission-openvpn/blob/master/README.md#network-configuration-options If you run into slow VPN issues, it may be the container is using a default .ovpn config. So you'd use something like this in a Override : OPENVPN_CONFIG=UK Southampton depending on your region/location.","title":"VPN Information"},{"location":"advanced/vpn-info/#what-vpn-services-are-available-to-use-through-dockstarter","text":"At the moment VPN is only available where we have found a easily configured container that runs as its own self contained unit. TransmissionVPN, SabNzbDVPN, DelugeVPN & rTorrentVPN are currently available.","title":"What VPN Services are available to use through DockSTARTer?"},{"location":"advanced/vpn-info/#vpn-tun-driver","text":"The VPN containers require an adjustment to your host system: echo \"iptable_mangle\" | sudo tee /etc/modules-load.d/iptable_mangle.conf echo \"tun\" | sudo tee /etc/modules-load.d/tun.conf sudo reboot","title":"VPN tun driver"},{"location":"advanced/vpn-info/#access-vpn-containers-remotely-using-letsencrypt","text":"If you're attempting to access the Web UI for one of your VPN containers (e.g. TransmissionVPN, DelugeVPN, etc.) from outside of your home network using LetsEncrypt, you will need to modify the LetsEncrypt configuration file to support the name difference. The sample configs are controlled by LSIO , not by DockSTARTer. So this change is required to get the VPN containers running remotely. The sample proxy configuration files found in .docker/config/letsencrypt/nginx/proxy-confs/ will need to be modified and as usual, have the .sample removed from the filename. You will also need to edit the appropriate proxy .conf . The below example uses the TransmissionVPN container as an example: Enter either sudo nano transmission.subfolder.conf or sudo nano transmission.subdomain.conf depending on your configuration desires and change the below line: Original set $upstream_transmission transmission; Modified set $upstream_transmission transmissionvpn; Save the file out and then restart your containers with a ds -c command.","title":"Access VPN containers remotely using LetsEncrypt"},{"location":"advanced/vpn-info/#how-can-i-check-if-my-vpn-is-working","text":"https://torguard.net/checkmytorrentipaddress.php http://www.doileak.com/ http://ipmagnet.services.cbcdn.com/ http://test.torrentprivacy.com/","title":"How can I check if my VPN is working?"},{"location":"advanced/vpn-info/#what-if-i-want-to-use-a-vpn-for-everything","text":"If you require VPN on all connections it is recommended to install OpenVPN as you normally would ( in /etc/openvpn etc etc) and then having the Docker service started and stopped by the up / down scripts. You can disable auto starting of the containers by disabling the docker service. On Ubuntu, I used sudo systemctl disable docker My vpnup.sh consists of #!/bin/bash if [[ -L \"/sbin/init\" ]]; then systemctl start docker else /etc/init.d/docker start fi and Down - #!/bin/bash if [[ -L \"/sbin/init\" ]]; then systemctl stop docker else /etc/init.d/docker stop fi If you make changes to the .env file, you will need to run the generator again. If you stop the OpenVPN service, thereby stopping Docker, the generation might not work. Start your OpenVPN service and run the generation again if it didn't work. cd ~/.docker/compose sudo ds -c","title":"What if I want to use a VPN for everything?"},{"location":"advanced/vpn-info/#pia-with-transmission","text":"For PIA VPN Configuration: These pages come in handy - * https://github.com/haugene/docker-transmission-openvpn/blob/master/README.md#network-configuration-options If you run into slow VPN issues, it may be the container is using a default .ovpn config. So you'd use something like this in a Override : OPENVPN_CONFIG=UK Southampton depending on your region/location.","title":"PIA with Transmission"},{"location":"apps/airdcpp/","text":"If you see the following error: No valid configuration found. Run the application with --configure parameter to set up initial configuration. Run the following commands to correct: docker stop airdcpp docker run --rm -it --volumes-from airdcpp gangefors/airdcpp-webclient --add-user You will be prompted to create a user and password, then run: docker start airdcpp","title":"AirDCpp"},{"location":"apps/bitwarden/","text":"Bitwarden Install When installing the Bitwarden container, the installer will install under Appdata directory as the root user, however once it is installed you can change the owner/group of it to whatever is required Run the below command (from a terminal) to change the permissions if required. sudo chown -R owner:group ~/.config/appdata/bitwarden Having the owner group change will allow you to edit the files if required without running into permission issues.","title":"BitWarden"},{"location":"apps/ddclient/","text":"Edit the included config to uncomment this line: use=web, web=checkip.dyndns.org/, web-skip='IP Address' # found after IP Address Then find your service of choice in the file and fill out the info as described. CloudFlare is recommended.","title":"ddclient"},{"location":"apps/delugevpn/","text":"layout: default If you're attempting to get access to the DelugeVPN WebUI remotely outside of your home network using LetsEncrypt you must follow the steps outlined in VPN Information .","title":"DelugeVPN"},{"location":"apps/delugevpn/#layout-default","text":"If you're attempting to get access to the DelugeVPN WebUI remotely outside of your home network using LetsEncrypt you must follow the steps outlined in VPN Information .","title":"layout: default"},{"location":"apps/duplicati/","text":"If you install Duplicati, you may be wondering what the important folders and files are to backup in case something goes wrong and you want to restore and be back up and running within minutes. Everything regarding DockSTARTer is found in /source like below (You can exclude .git and .github):","title":"Duplicati"},{"location":"apps/homeassistant/","text":"Environment Variable You may want to override homeassistant with environment variable PYTHONWARNINGS=\"ignore:Unverified HTTPS request\" if you recevieve warning each 10 second for e.g. device tracking of self-signed Unifi Controller SSL certificated. Reference: https://community.home-assistant.io/t/endless-insecurerequestwarning-errors-with-unifi/31831/12","title":"Home Assistant"},{"location":"apps/homeassistant/#environment-variable","text":"You may want to override homeassistant with environment variable PYTHONWARNINGS=\"ignore:Unverified HTTPS request\" if you recevieve warning each 10 second for e.g. device tracking of self-signed Unifi Controller SSL certificated. Reference: https://community.home-assistant.io/t/endless-insecurerequestwarning-errors-with-unifi/31831/12","title":"Environment Variable"},{"location":"apps/letsencrypt/","text":"General Setup Out of the box, the LetsEncrypt container created by linuxserver.io performs reverse proxy functions using NGINX and automatic https encrypted connections using certificates provided by LetsEncrypt . More on this container can be found here . To configure your reverse proxy, consider if you want to use subfolders (ie. domain.com/portainer) or subdomains (ie. portainer.domain.com). Subdomains will take more configuration, as DNS entries and certificate subject alternate names are required. The first thing to setup is your domain and email settings in .docker/compose/.env under LETSENCRYPT. Set the LETSENCRYPT_EMAIL and LETSENCRYPT_URL . If using subdomains ensure to add each subdomain to LETSENCRYPT_SUBDOMAINS as each subdomain prefix (ie. LETSENCRYPT_SUBDOMAINS=portainer,deluge,pihole . There are a number of sample proxy configuration files found in ~/.config/appdata/letsencrypt/nginx/proxy-confs/ and in most cases will just need the .sample removed from the filename. Currently not every applicable app has an example configuration and are still being tested. Subfolder Example: cp ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subfolder.conf.sample ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subfolder.conf This will make Portainer available at domain.com/portainer Subdomain Example: cp ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subdomain.conf.sample ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subdomain.conf and will enable the service at portainer.domain.com Each time you change a proxy conf file you will need to restart the LetsEncrypt container: docker restart letsencrypt Part 2 If you haven't forwarded ports for LE before container was setup, stop container, delete letsencrypt config folder, run ds -c , and you should be good to go. If you are not using subdomains: 1. Blank out LETSENCRYPT_SUBDOMAINS in ~/.docker/compose/.env Like so: LETSENCRYPT_SUBDOMAINS= Fill in EMAIL, URL, like so: LETSENCRYPT_EMAIL=user@domain.com LETSENCRYPT_URL=appropriateaddress.com cp organizr.subfolder.conf.sample organizr.subfolder.conf in ~/.config/appdata/letsencrypt/nginx/proxy-confs Edit ~/.config/appdata/letsencrypt/nginx/site-confs/default and comment out the following (As shown): # location / { # try_files $uri $uri/ /index.html /index.php?$args =404; # } Why does my LetsEncrypt proxy configuration for (insert app here) say one port, but I have to access it with another port? Generally speaking, your configuration does point to the port you specify, which is correct. DockSTARTer sets your app to 8080 on your internal network, but docker has a docker network as well. On that network your app runs on the default port for the app! That is how containers like LetsEncrypt and Organizr (For example) communicate. How do i automatically make http calls redirect to https for letsencrypt? This change will make it so that if you type http://blahblah it will redirect to https://blahblah Edit ~/.config/appdata/nginx/site-confs/default Uncomment the relevant part of the file (see below) # listening on port 80 disabled by default, remove the \"#\" signs to enable # redirect all traffic to https server { listen 80; listen [::]:80; server_name _; return 301 https://$host$request_uri; } Restart the letsencrypt container docker restart letsencrypt How do i redirect the main index.html page to organizr? If you want https://mydomain.duckdns.org to load organizr you can do the following. Goto ~/.config/appdata/letsencrypt/www Replace index.html with index.php Edit index.php and replace it with the following single line <?php header(\"Location: https://organizr.mydomain.duckdns.org\"); ?> Restart the letsencrypt container docker restart letsencrypt","title":"Let's Encrypt (Certbot)"},{"location":"apps/letsencrypt/#general-setup","text":"Out of the box, the LetsEncrypt container created by linuxserver.io performs reverse proxy functions using NGINX and automatic https encrypted connections using certificates provided by LetsEncrypt . More on this container can be found here . To configure your reverse proxy, consider if you want to use subfolders (ie. domain.com/portainer) or subdomains (ie. portainer.domain.com). Subdomains will take more configuration, as DNS entries and certificate subject alternate names are required. The first thing to setup is your domain and email settings in .docker/compose/.env under LETSENCRYPT. Set the LETSENCRYPT_EMAIL and LETSENCRYPT_URL . If using subdomains ensure to add each subdomain to LETSENCRYPT_SUBDOMAINS as each subdomain prefix (ie. LETSENCRYPT_SUBDOMAINS=portainer,deluge,pihole . There are a number of sample proxy configuration files found in ~/.config/appdata/letsencrypt/nginx/proxy-confs/ and in most cases will just need the .sample removed from the filename. Currently not every applicable app has an example configuration and are still being tested. Subfolder Example: cp ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subfolder.conf.sample ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subfolder.conf This will make Portainer available at domain.com/portainer Subdomain Example: cp ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subdomain.conf.sample ~/.config/appdata/letsencrypt/nginx/proxy-confs/portainer.subdomain.conf and will enable the service at portainer.domain.com Each time you change a proxy conf file you will need to restart the LetsEncrypt container: docker restart letsencrypt","title":"General Setup"},{"location":"apps/letsencrypt/#part-2","text":"If you haven't forwarded ports for LE before container was setup, stop container, delete letsencrypt config folder, run ds -c , and you should be good to go. If you are not using subdomains: 1. Blank out LETSENCRYPT_SUBDOMAINS in ~/.docker/compose/.env Like so: LETSENCRYPT_SUBDOMAINS= Fill in EMAIL, URL, like so: LETSENCRYPT_EMAIL=user@domain.com LETSENCRYPT_URL=appropriateaddress.com cp organizr.subfolder.conf.sample organizr.subfolder.conf in ~/.config/appdata/letsencrypt/nginx/proxy-confs Edit ~/.config/appdata/letsencrypt/nginx/site-confs/default and comment out the following (As shown): # location / { # try_files $uri $uri/ /index.html /index.php?$args =404; # }","title":"Part 2"},{"location":"apps/letsencrypt/#why-does-my-letsencrypt-proxy-configuration-for-insert-app-here-say-one-port-but-i-have-to-access-it-with-another-port","text":"Generally speaking, your configuration does point to the port you specify, which is correct. DockSTARTer sets your app to 8080 on your internal network, but docker has a docker network as well. On that network your app runs on the default port for the app! That is how containers like LetsEncrypt and Organizr (For example) communicate.","title":"Why does my LetsEncrypt proxy configuration for (insert app here) say one port, but I have to access it with another port?"},{"location":"apps/letsencrypt/#how-do-i-automatically-make-http-calls-redirect-to-https-for-letsencrypt","text":"This change will make it so that if you type http://blahblah it will redirect to https://blahblah Edit ~/.config/appdata/nginx/site-confs/default Uncomment the relevant part of the file (see below) # listening on port 80 disabled by default, remove the \"#\" signs to enable # redirect all traffic to https server { listen 80; listen [::]:80; server_name _; return 301 https://$host$request_uri; } Restart the letsencrypt container docker restart letsencrypt","title":"How do i automatically make http calls redirect to https for letsencrypt?"},{"location":"apps/letsencrypt/#how-do-i-redirect-the-main-indexhtml-page-to-organizr","text":"If you want https://mydomain.duckdns.org to load organizr you can do the following. Goto ~/.config/appdata/letsencrypt/www Replace index.html with index.php Edit index.php and replace it with the following single line <?php header(\"Location: https://organizr.mydomain.duckdns.org\"); ?> Restart the letsencrypt container docker restart letsencrypt","title":"How do i redirect the main index.html page to organizr?"},{"location":"apps/logarr/","text":"Logarr configuration has sharing to the logs enabled by default. From within the Logarr container, this is accessible via the /var/log/logarrlogs path. Which is mapped to your ~/.config/appdata path of your host machine. For Logarr you will need to edit the config.php file to point to the correct log files. This file is located in the ~/.config/appdata/logarr/www/logarr/assets/ folder of your host machine. Edit the included config to change these lines: \"Sonarr\" => '/var/log/logarrlogs//sonarr/logs/sonarr.txt', \"Radarr\" => '/var/log/logarrlogs/radarr/logs/radarr.txt',","title":"Logarr"},{"location":"apps/netdata/","text":"layout: default By default, netdata will pull from a UID for the container itself to display in the list of netdata servers you have, so you would see something like '0f2342dac'. To define this and make it more readable/recognizable for you (In case you have multiple netdata servers): 1. Stop the netdata container. 2. Edit or Create this file: ~/.docker/compose/docker-compose.override.yml and change ${HOSTNAME} to friendlynamefornetdata . 3. Once this is done, re-run sudo ds -c For Reverse Proxy configuration, we'll use this template from guys who already thought of this at organizrTools . Template from OrganizrTools Example: location = /netdata { return 301 /netdata/; } location ~ /netdata/(?<ndpath>.*) { include /config/nginx/proxy.conf; resolver 127.0.0.11 valid=30s; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass_request_headers on; proxy_set_header Connection \"keep-alive\"; proxy_store off; proxy_pass http://netdata:19999/$ndpath$is_args$args; proxy_headers_hash_max_size 512; proxy_headers_hash_bucket_size 64; gzip on; gzip_proxied any; gzip_types *; } Notifications Add health_alarm_notify.conf to your netdata config directory. Populate the notification service(s) you want with login, tokens or similar that is applicable. Instructions found in health_alarm_notify.conf . Create health.d directory in netdata config directory. Add conf files from health.d for which modules you want alarms. Also note that one can remove specific alarms by commenting them in .conf files. Get CPU temp from raspberry pi Netdata will not pick up cpu temp per default for raspberry pi. To activate chart for pi cpu temp add a file with name charts.d.conf in netdata config directory and add the following line. sensors=force Get data for home assistant To identify the correct data group and element to input in netdata home assistant component use http://yournetdataip:19999/api/v1/allmetrics?format=json Monitor services with netdata Create python.d directory in netdata config directory. Add httpcheck.conf to your python.d directory. Edit according to instructions in file, suggestion is to add after last line in conf file. See example below. # This plugin is intended for simple cases. Currently, the accuracy of the response time is low and should be used as reference only. Hydra: url: 'http://192.168.86.60:5076/nzbhydra/' timeout: 1 redirect: no status_accepted: - 200 regex: '.*hydra.*' Ombi: url: 'http://192.168.86.60:3579/ombi/landingpage' timeout: 1 redirect: yes status_accepted: - 200 regex: '.*ombi.*' You will now get charts in netdata for ombi and hydra. Please add your ip and ports accordingly. To get alarms add httpcheck.conf to your health.d directory. Don't forget to comment the unwanted alarms. Slow response alarm can be quite annoying. Netdata badges Coming soon.","title":"Netdata"},{"location":"apps/netdata/#layout-default","text":"By default, netdata will pull from a UID for the container itself to display in the list of netdata servers you have, so you would see something like '0f2342dac'. To define this and make it more readable/recognizable for you (In case you have multiple netdata servers): 1. Stop the netdata container. 2. Edit or Create this file: ~/.docker/compose/docker-compose.override.yml and change ${HOSTNAME} to friendlynamefornetdata . 3. Once this is done, re-run sudo ds -c For Reverse Proxy configuration, we'll use this template from guys who already thought of this at organizrTools . Template from OrganizrTools Example: location = /netdata { return 301 /netdata/; } location ~ /netdata/(?<ndpath>.*) { include /config/nginx/proxy.conf; resolver 127.0.0.11 valid=30s; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass_request_headers on; proxy_set_header Connection \"keep-alive\"; proxy_store off; proxy_pass http://netdata:19999/$ndpath$is_args$args; proxy_headers_hash_max_size 512; proxy_headers_hash_bucket_size 64; gzip on; gzip_proxied any; gzip_types *; }","title":"layout: default"},{"location":"apps/netdata/#notifications","text":"Add health_alarm_notify.conf to your netdata config directory. Populate the notification service(s) you want with login, tokens or similar that is applicable. Instructions found in health_alarm_notify.conf . Create health.d directory in netdata config directory. Add conf files from health.d for which modules you want alarms. Also note that one can remove specific alarms by commenting them in .conf files.","title":"Notifications"},{"location":"apps/netdata/#get-cpu-temp-from-raspberry-pi","text":"Netdata will not pick up cpu temp per default for raspberry pi. To activate chart for pi cpu temp add a file with name charts.d.conf in netdata config directory and add the following line. sensors=force","title":"Get CPU temp from raspberry pi"},{"location":"apps/netdata/#get-data-for-home-assistant","text":"To identify the correct data group and element to input in netdata home assistant component use http://yournetdataip:19999/api/v1/allmetrics?format=json","title":"Get data for home assistant"},{"location":"apps/netdata/#monitor-services-with-netdata","text":"Create python.d directory in netdata config directory. Add httpcheck.conf to your python.d directory. Edit according to instructions in file, suggestion is to add after last line in conf file. See example below. # This plugin is intended for simple cases. Currently, the accuracy of the response time is low and should be used as reference only. Hydra: url: 'http://192.168.86.60:5076/nzbhydra/' timeout: 1 redirect: no status_accepted: - 200 regex: '.*hydra.*' Ombi: url: 'http://192.168.86.60:3579/ombi/landingpage' timeout: 1 redirect: yes status_accepted: - 200 regex: '.*ombi.*' You will now get charts in netdata for ombi and hydra. Please add your ip and ports accordingly. To get alarms add httpcheck.conf to your health.d directory. Don't forget to comment the unwanted alarms. Slow response alarm can be quite annoying.","title":"Monitor services with netdata"},{"location":"apps/netdata/#netdata-badges","text":"Coming soon.","title":"Netdata badges"},{"location":"apps/nextcloud/","text":"If you are running the DockSTARTer Nextcloud container behind a LetsEncrypt Reverse gateway, you may need to add a extra line to the NextCloud config.php file so it can find it. you will be able to access the web page all OK, but any apps may timeout or return an invalid password run the below command and add the line to the the config.php file before the ); nano /config/www/nextcloud/config/config.php 'overwritehost' => 'hostname', where your 'hostname' is the URL you use to access your NextCloud web interface, make sure you include the comma at the end. this will allow the apps to pass the username/password through to the application","title":"NextCloud"},{"location":"apps/openvpnas/","text":"Information pulled from Docker Hub and edited for relevance. Setting up the application The admin interface is available at https:// :943/admin with a default user/password of admin/password During first login, make sure that the \"Authentication\" in the webui is set to \"Local\" instead of \"PAM\". Then set up the user accounts with their password (user accounts created under PAM do not survive container update or recreation). The \"admin\" account is a system (PAM) account and after container update or recreation, its password reverts back to the default. It is highly recommended to block this user's access for security reasons: 1) Set another user as an admin, 2) Delete the \"admin\" user in the gui, 3) Modify the as.conf file under config/etc and replace the line boot_pam_users.0=admin with #boot_pam_users.0=admin (this only has to be done once and will survive container recreation) Server Network Settings Make sure to change Hostname or IP Address to your public IP or public DNS name. It defaults to the docker internal IP. Also, and I think this goes without saying, make sure to forward the correct ports on your firewall to your host IP. LetsEncrypt Subdomain Config Sample LetsEncrypt Config Here","title":"OpenVPN-AS"},{"location":"apps/openvpnas/#setting-up-the-application","text":"The admin interface is available at https:// :943/admin with a default user/password of admin/password During first login, make sure that the \"Authentication\" in the webui is set to \"Local\" instead of \"PAM\". Then set up the user accounts with their password (user accounts created under PAM do not survive container update or recreation). The \"admin\" account is a system (PAM) account and after container update or recreation, its password reverts back to the default. It is highly recommended to block this user's access for security reasons: 1) Set another user as an admin, 2) Delete the \"admin\" user in the gui, 3) Modify the as.conf file under config/etc and replace the line boot_pam_users.0=admin with #boot_pam_users.0=admin (this only has to be done once and will survive container recreation)","title":"Setting up the application"},{"location":"apps/openvpnas/#server-network-settings","text":"Make sure to change Hostname or IP Address to your public IP or public DNS name. It defaults to the docker internal IP. Also, and I think this goes without saying, make sure to forward the correct ports on your firewall to your host IP.","title":"Server Network Settings"},{"location":"apps/openvpnas/#letsencrypt-subdomain-config","text":"Sample LetsEncrypt Config Here","title":"LetsEncrypt Subdomain Config"},{"location":"apps/ouroboros/","text":"Full documentation can be found at the Ouroboros Wiki For information about update notifications see https://github.com/pyouroboros/ouroboros/wiki/Notifications and https://github.com/pyouroboros/ouroboros/wiki/Notifications","title":"Ouroboros"},{"location":"apps/pihole/","text":"Pi-hole takes over the local DNS service and may conflict with existing DNS services on your server. Ubuntu 18.04 currently uses systemd-resolv to server DNS and needs to be configured to either give up port 53 or be disabled. Netplan setup On Ubuntu 18.04 and newer you will have netplan controlling your network and should see https://netplan.io/ for examples on how to configure it. You need to set your nameserver to use your LAN's DNS or a public DNS such as 1.1.1.1 before proceeding with any instructions below. Resolvconf On Ubuntu 18.04, resolvconf was removed as the default means to control DNS. In addition to the settings mentioned regarding netplan, we recommend setting up resolvconf. To install run sudo apt install resolvconf Edit /etc/resolvconf/resolv.conf.d/head using sudo and enter nameserver 1.1.1.1 on the first uncommented line. Restart the service sudo service resolvconf restart Stop systemd-resolv from listening on port 53 Edit /etc/systemd/resolved.conf and set DNSStubListener=no (make sure it is not commented out with a # at the beginning of the line) and then run sudo systemctl restart systemd-resolved If that does not work you can try the following: Stop and disable systemd-resolv (only if the above does not work) sudo systemctl stop systemd-resolv.service sudo systemctl disable systemd-resolv.service Name resolution for localhost In most cases it might be required to set your localhost name in /etc/hosts 127.0.0.1 machinename.localhost machinename 127.0.0.1 domain.com","title":"Pi-hole"},{"location":"apps/pihole/#netplan-setup","text":"On Ubuntu 18.04 and newer you will have netplan controlling your network and should see https://netplan.io/ for examples on how to configure it. You need to set your nameserver to use your LAN's DNS or a public DNS such as 1.1.1.1 before proceeding with any instructions below.","title":"Netplan setup"},{"location":"apps/pihole/#resolvconf","text":"On Ubuntu 18.04, resolvconf was removed as the default means to control DNS. In addition to the settings mentioned regarding netplan, we recommend setting up resolvconf. To install run sudo apt install resolvconf Edit /etc/resolvconf/resolv.conf.d/head using sudo and enter nameserver 1.1.1.1 on the first uncommented line. Restart the service sudo service resolvconf restart","title":"Resolvconf"},{"location":"apps/pihole/#stop-systemd-resolv-from-listening-on-port-53","text":"Edit /etc/systemd/resolved.conf and set DNSStubListener=no (make sure it is not commented out with a # at the beginning of the line) and then run sudo systemctl restart systemd-resolved If that does not work you can try the following:","title":"Stop systemd-resolv from listening on port 53"},{"location":"apps/pihole/#stop-and-disable-systemd-resolv-only-if-the-above-does-not-work","text":"sudo systemctl stop systemd-resolv.service sudo systemctl disable systemd-resolv.service","title":"Stop and disable systemd-resolv (only if the above does not work)"},{"location":"apps/pihole/#name-resolution-for-localhost","text":"In most cases it might be required to set your localhost name in /etc/hosts 127.0.0.1 machinename.localhost machinename 127.0.0.1 domain.com","title":"Name resolution for localhost"},{"location":"apps/plex/","text":"Plex is telling me to login and then not directing me to the server I just set up, why? Upon starting up Plex for the first time, it's very likely you'll need to follow these steps: NOTE - You have 5 minutes from the time you generate your Claim Token to get Plex back up and running, so you may need to work fast!) 1. Run docker stop plex && docker rm plex 2. Run mv ~/.config/appdata/plex/ ~/.config/appdata/plex.bak/ 3. Grab your Plex Claim Token from here: https://www.plex.tv/claim 4. Edit ~/.docker/compose/.env 5. Set PLEX_CLAIM= to use the claim token you generated from the link. 6. Run sudo ds -c up 7. Go back to http://x.x.x.x:32400/web (x.x.x.x being the IP of your Plex server) and you should be able to complete FTS. If the above does not work repeat the steps a second time but also with step 4 in your .env set PLEX_NETWORK_MODE=host . After claiming your server set PLEX_NETWORK_MODE= (back to blank). Everything's gone to crap, and I need to re-make my server. What do I do? Thankfully, some of this information is well documented (but not easily found) over on Plex's website here! 1. Moving an installation to another system: https://support.plex.tv/articles/201370363-move-an-install-to-another-system/ 2. Where is the Plex Media Server data directory? https://support.plex.tv/articles/202915258-where-is-the-plex-media-server-data-directory-located/ If you would like to have Plex use a GPU that is attached to your DockSTARTer host, you can do this using an override like so: devices: - /dev/dri:/dev/dri Refer to this forum post for details: Using Hardware Acceleration in Docker","title":"Plex"},{"location":"apps/plex/#plex-is-telling-me-to-login-and-then-not-directing-me-to-the-server-i-just-set-up-why","text":"Upon starting up Plex for the first time, it's very likely you'll need to follow these steps: NOTE - You have 5 minutes from the time you generate your Claim Token to get Plex back up and running, so you may need to work fast!) 1. Run docker stop plex && docker rm plex 2. Run mv ~/.config/appdata/plex/ ~/.config/appdata/plex.bak/ 3. Grab your Plex Claim Token from here: https://www.plex.tv/claim 4. Edit ~/.docker/compose/.env 5. Set PLEX_CLAIM= to use the claim token you generated from the link. 6. Run sudo ds -c up 7. Go back to http://x.x.x.x:32400/web (x.x.x.x being the IP of your Plex server) and you should be able to complete FTS. If the above does not work repeat the steps a second time but also with step 4 in your .env set PLEX_NETWORK_MODE=host . After claiming your server set PLEX_NETWORK_MODE= (back to blank).","title":"Plex is telling me to login and then not directing me to the server I just set up, why?"},{"location":"apps/plex/#everythings-gone-to-crap-and-i-need-to-re-make-my-server-what-do-i-do","text":"Thankfully, some of this information is well documented (but not easily found) over on Plex's website here! 1. Moving an installation to another system: https://support.plex.tv/articles/201370363-move-an-install-to-another-system/ 2. Where is the Plex Media Server data directory? https://support.plex.tv/articles/202915258-where-is-the-plex-media-server-data-directory-located/ If you would like to have Plex use a GPU that is attached to your DockSTARTer host, you can do this using an override like so: devices: - /dev/dri:/dev/dri Refer to this forum post for details: Using Hardware Acceleration in Docker","title":"Everything's gone to crap, and I need to re-make my server. What do I do?"},{"location":"apps/portainer/","text":"To give Portainer the ability to go directly to your IP name of your server Log onto your Portainer server and then select Settings > Endpoints > your local endpoint (mine was primary) > and change \"Public IP\" it'll update those links to work put whatever IP you want to use in the link eg: 192.168.1.X","title":"Portainer"},{"location":"apps/samba/","text":"Description Samba is using the SMB protocol to share Linux mounts, which then are accessible and mountable on e.g. a Windows computer. By default, Samba will share all media directories and Docker config directory over SMB on the host. These shares are protected with username DockSTARTer and password DockSTARTer . Access Shares Replace host with your DNS or IP-address of your Docker host. * \\\\host\\Docker Config * \\\\host\\Downloads * \\\\host\\Comics * \\\\host\\Books * \\\\host\\Movies * \\\\host\\Music * \\\\host\\TV Related Mounting Windows share in Linux See SMB Mounting .","title":"Samba"},{"location":"apps/samba/#description","text":"Samba is using the SMB protocol to share Linux mounts, which then are accessible and mountable on e.g. a Windows computer. By default, Samba will share all media directories and Docker config directory over SMB on the host. These shares are protected with username DockSTARTer and password DockSTARTer .","title":"Description"},{"location":"apps/samba/#access-shares","text":"Replace host with your DNS or IP-address of your Docker host. * \\\\host\\Docker Config * \\\\host\\Downloads * \\\\host\\Comics * \\\\host\\Books * \\\\host\\Movies * \\\\host\\Music * \\\\host\\TV","title":"Access Shares"},{"location":"apps/samba/#related","text":"","title":"Related"},{"location":"apps/samba/#mounting-windows-share-in-linux","text":"See SMB Mounting .","title":"Mounting Windows share in Linux"},{"location":"apps/watchtower/","text":"Override for Notifications to your favorite method (E-mail, Slack/Discord, MS Teams are supported in Watchtower currently): You would want to put this in your docker-compose.override.yml For Discord/Slack: watchtower: environment: - WATCHTOWER_NOTIFICATIONS=slack - WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL=https://url.discord.com/slack - WATCHTOWER_NOTIFICATION_SLACK_IDENTIFIER=watchtower-server-1 For E-Mail: watchtower: environment: - WATCHTOWER_NOTIFICATION_EMAIL_FROM=myemail@gmail.com - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD=secretPassword - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT=587 - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER=myemail@gmail.com - WATCHTOWER_NOTIFICATION_EMAIL_SERVER=smtp.gmail.com - WATCHTOWER_NOTIFICATION_EMAIL_TO=myemail@gmail.com - WATCHTOWER_NOTIFICATIONS=email This is what you could have had in your override previously : version: \"3.4\" # this must match the version in docker-compose.yml services: netdata: hostname: newhostname So now your override would look like this: version: \"3.4\" # this must match the version in docker-compose.yml services: netdata: hostname: newhostname watchtower: environment: - WATCHTOWER_NOTIFICATIONS=slack - WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL=https://url.discord.com/slack - WATCHTOWER_NOTIFICATION_SLACK_IDENTIFIER=watchtower-server-1","title":"Watchtower"},{"location":"basics/available-apps/","text":"Please browse the repo here to see which apps are available: https://github.com/GhostWriters/DockSTARTer/tree/master/compose/.apps If an app folder exists then it is available for x86_64. Inside the folder will be files for ARMHF and AARCH64 if they are supported. If ARMHF is present but AARCH64 is not it will fall back to using ARMHF. You can see descriptions of each app in the GUI or in the main yml file for each app in the repository.","title":"Available Applications"},{"location":"basics/faq/","text":"What Is DockSTARTer ? DockSTARTer is a program that starts a bunch of different containers within a common framework to make it easy to install all your favorite apps and tools. System Requirements Supported Operating Systems We imagine DockSTARTer will behave nicely on any systems supported by the https://get.docker.com/ script. Your experiences with individual containers may vary though based primarily on the availability of the container for your hardware architecture. Supported Hardware Raspberry Pi or better? ARM architecture will be limited compared to x86_64 as far as app selection. Windows Support? Have you considered a Virtual Machine? Windows 8.1 has VM support built in. This has some benefits over running the same programs on windows, it allows you to essentially \"sandbox\" all your apps and best of all, you'll have a reason to still be here! Read this guide here to get up and running with Linux essentially running as a app within Windows. Just remember to get the server ISO, Linux is generally pretty lean but an idle fresh install of Ubuntu (server) uses less than 200mb of memory and about 5gb minimum storage. Ouroboros and Portainer: I didn't select them but they installed anyway? They are installed by default and the below blurbs from their official documentation should explain why but you can disable either or both of them if you want. Ouroboros will monitor (all or specified) running docker containers and update them to the (latest or tagged) available image in the remote registry. Portainer allows you to manage your Docker stacks, containers, images, volumes, networks and more! It is compatible with the standalone Docker engine and with Docker Swarm. In short, Ouroboros keeps your Containers up to date and Portainer gives you a WebGUI for starting and stopping Containers. Have a look, at www.appropriateaddress.com:9000 . DockSTARTer previously enabled Watchtower by default before Ouroboros. The two do almost the same thing, but Ouroboros has more options. General troubleshooting help You can see the (quite helpful) logs of each container with a Quick action in Portainer: Reported Issues Creating network \"compose_default\" with the default driver ERROR: could not find an available, non-overlapping IPv4 address pool among the defaults to assign to the network This error can occur if your connected to a VPN while setting up the containers. Simply temporarily disconnect your VPN connection until the containers have been created and then reconnect again. Starting containers and getting the following or a similar error message: \"listen udp 0.0.0.0:5353: bind: address already in use\" As you could probably guess this means an application (most likely plex) is trying to use a port that is already in use. You can check which application it is with: sudo lsof -i :<myport> So in this example it would be: sudo lsof -i :5353 which will show you that Google Chrome is using the port you need. In this case you could just close Chrome, but there may be applications you need to uninstall for this to work properly.","title":"Frequently Asked Questions"},{"location":"basics/faq/#what-is-dockstarter","text":"DockSTARTer is a program that starts a bunch of different containers within a common framework to make it easy to install all your favorite apps and tools.","title":"What Is DockSTARTer ?"},{"location":"basics/faq/#system-requirements","text":"","title":"System Requirements"},{"location":"basics/faq/#supported-operating-systems","text":"We imagine DockSTARTer will behave nicely on any systems supported by the https://get.docker.com/ script. Your experiences with individual containers may vary though based primarily on the availability of the container for your hardware architecture.","title":"Supported Operating Systems"},{"location":"basics/faq/#supported-hardware","text":"Raspberry Pi or better? ARM architecture will be limited compared to x86_64 as far as app selection.","title":"Supported Hardware"},{"location":"basics/faq/#windows-support","text":"Have you considered a Virtual Machine? Windows 8.1 has VM support built in. This has some benefits over running the same programs on windows, it allows you to essentially \"sandbox\" all your apps and best of all, you'll have a reason to still be here! Read this guide here to get up and running with Linux essentially running as a app within Windows. Just remember to get the server ISO, Linux is generally pretty lean but an idle fresh install of Ubuntu (server) uses less than 200mb of memory and about 5gb minimum storage.","title":"Windows Support?"},{"location":"basics/faq/#ouroboros-and-portainer-i-didnt-select-them-but-they-installed-anyway","text":"They are installed by default and the below blurbs from their official documentation should explain why but you can disable either or both of them if you want. Ouroboros will monitor (all or specified) running docker containers and update them to the (latest or tagged) available image in the remote registry. Portainer allows you to manage your Docker stacks, containers, images, volumes, networks and more! It is compatible with the standalone Docker engine and with Docker Swarm. In short, Ouroboros keeps your Containers up to date and Portainer gives you a WebGUI for starting and stopping Containers. Have a look, at www.appropriateaddress.com:9000 . DockSTARTer previously enabled Watchtower by default before Ouroboros. The two do almost the same thing, but Ouroboros has more options.","title":"Ouroboros and Portainer: I didn't select them but they installed anyway?"},{"location":"basics/faq/#general-troubleshooting-help","text":"You can see the (quite helpful) logs of each container with a Quick action in Portainer:","title":"General troubleshooting help"},{"location":"basics/faq/#reported-issues","text":"","title":"Reported Issues"},{"location":"basics/faq/#creating-network-compose_default-with-the-default-driver-error-could-not-find-an-available-non-overlapping-ipv4-address-pool-among-the-defaults-to-assign-to-the-network","text":"This error can occur if your connected to a VPN while setting up the containers. Simply temporarily disconnect your VPN connection until the containers have been created and then reconnect again.","title":"Creating network \"compose_default\" with the default driver ERROR: could not find an available, non-overlapping IPv4 address pool among the defaults to assign to the network"},{"location":"basics/faq/#starting-containers-and-getting-the-following-or-a-similar-error-message-listen-udp-00005353-bind-address-already-in-use","text":"As you could probably guess this means an application (most likely plex) is trying to use a port that is already in use. You can check which application it is with: sudo lsof -i :<myport> So in this example it would be: sudo lsof -i :5353 which will show you that Google Chrome is using the port you need. In this case you could just close Chrome, but there may be applications you need to uninstall for this to work properly.","title":"Starting containers and getting the following or a similar error message: \"listen udp 0.0.0.0:5353: bind: address already in use\""},{"location":"basics/migration/","text":"Migrating from local installs Stop the service for the existing app (so that ports are available) Start the app using DockSTARTer so that the config folder structure is created ( ~/.config/appdata/appname by default) Stop the app's docker container ( docker stop appname ) Locate the config of the local installation and copy it to ~/.config/appdata/appname (only grab the required files) Start the app ( sudo ds -c ) Inside the app's config, or settings web interface, adjust the folder locations that make use of files on the disk to match the docker volumes for the container Adjust the app config to communicate with other existing apps (both in and out of docker as needed) Optionally uninstall/remove original app and dependencies Example Sonarr's config is commonly found in ~/.config/NzbDrone . Following the instructions above, all files in ~/.config/NzbDrone would be copied to ~/.config/appdata/sonarr . After starting the new Sonarr in Docker, modify the Root Folder settings to tell Sonarr where your files are. DockSTARTer maps the true location of your media folders to locations the container expects to see such as /tv in the case of Sonarr, so that is where you will set your root folder. You will also need to modify your settings that have Sonarr connect to other apps such as Usenet or Torrent download clients. Rather than an IP address or localhost you would just use the name of the download client app, ex: nzbget as the hostname. The same would apply for any connections between any app.","title":"How to Migrate to DS"},{"location":"basics/migration/#migrating-from-local-installs","text":"Stop the service for the existing app (so that ports are available) Start the app using DockSTARTer so that the config folder structure is created ( ~/.config/appdata/appname by default) Stop the app's docker container ( docker stop appname ) Locate the config of the local installation and copy it to ~/.config/appdata/appname (only grab the required files) Start the app ( sudo ds -c ) Inside the app's config, or settings web interface, adjust the folder locations that make use of files on the disk to match the docker volumes for the container Adjust the app config to communicate with other existing apps (both in and out of docker as needed) Optionally uninstall/remove original app and dependencies","title":"Migrating from local installs"},{"location":"basics/migration/#example","text":"Sonarr's config is commonly found in ~/.config/NzbDrone . Following the instructions above, all files in ~/.config/NzbDrone would be copied to ~/.config/appdata/sonarr . After starting the new Sonarr in Docker, modify the Root Folder settings to tell Sonarr where your files are. DockSTARTer maps the true location of your media folders to locations the container expects to see such as /tv in the case of Sonarr, so that is where you will set your root folder. You will also need to modify your settings that have Sonarr connect to other apps such as Usenet or Torrent download clients. Rather than an IP address or localhost you would just use the name of the download client app, ex: nzbget as the hostname. The same would apply for any connections between any app.","title":"Example"},{"location":"basics/port-conflicts/","text":"Issue/Problem: During configuration the script exits with an error like the following: ERROR: for plex Cannot start service plex: driver failed programming external connectivity on endpoint plex (5a4d78fd5ff6c4c1a978ef31): Error starting userland proxy: listen udp 0.0.0.0:5353: bind: address already in use ERROR: Encountered errors while bringing up the project. 2019-02-13 17:38:19 [FATAL] Docker Compose failed. This is due to another service that has occupied that port disallowing DockSTARTer from installing a service on that port. Troubleshooting Methods: As DockSTARTer will check and fail if another service is occupying the port, it is necessary to locate and deal with the conflict. One way is to locate the service currently occupying the port. You can do the following: sudo netstat -ltunp | grep -w ':<port>' example: sudo netstat -ltunp | grep -w ':8080' Once you locate the offending service then you can choose what to do. Resolutions/Solutions: Example: If you have avahi-daemon installed this will conflict with udp/5353 port usage for iTunes in Plex if selected. This will cause the script to exit with an [ERROR] and a [FATAL]. One resolution is to change the port being bound during configuration. During configuration change the external port exposed from 5353 to 5354 (or another unused port) . This will resolve the conflict. Another resolution would be to remove the software that is in conflict. Again as the example above. If you are not using mDNS resolution then avahi-daemon would be unnecessary. Simply remove the package with apt remove avahi-daemon from the base server. This will remove the offending service and allow the port to be used by the Docker service.","title":"Port Conflicts"},{"location":"basics/port-conflicts/#issueproblem","text":"During configuration the script exits with an error like the following: ERROR: for plex Cannot start service plex: driver failed programming external connectivity on endpoint plex (5a4d78fd5ff6c4c1a978ef31): Error starting userland proxy: listen udp 0.0.0.0:5353: bind: address already in use ERROR: Encountered errors while bringing up the project. 2019-02-13 17:38:19 [FATAL] Docker Compose failed. This is due to another service that has occupied that port disallowing DockSTARTer from installing a service on that port.","title":"Issue/Problem:"},{"location":"basics/port-conflicts/#troubleshooting-methods","text":"As DockSTARTer will check and fail if another service is occupying the port, it is necessary to locate and deal with the conflict. One way is to locate the service currently occupying the port. You can do the following: sudo netstat -ltunp | grep -w ':<port>' example: sudo netstat -ltunp | grep -w ':8080' Once you locate the offending service then you can choose what to do.","title":"Troubleshooting Methods:"},{"location":"basics/port-conflicts/#resolutionssolutions","text":"Example: If you have avahi-daemon installed this will conflict with udp/5353 port usage for iTunes in Plex if selected. This will cause the script to exit with an [ERROR] and a [FATAL]. One resolution is to change the port being bound during configuration. During configuration change the external port exposed from 5353 to 5354 (or another unused port) . This will resolve the conflict. Another resolution would be to remove the software that is in conflict. Again as the example above. If you are not using mDNS resolution then avahi-daemon would be unnecessary. Simply remove the package with apt remove avahi-daemon from the base server. This will remove the offending service and allow the port to be used by the Docker service.","title":"Resolutions/Solutions:"}]}